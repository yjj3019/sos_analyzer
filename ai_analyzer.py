#!/usr/bin/env python3
"""
sosreport ì••ì¶• íŒŒì¼ AI ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„± ëª¨ë“ˆ
sosreport ì••ì¶• íŒŒì¼ì„ ì…ë ¥ë°›ì•„ ì••ì¶• í•´ì œ, ë°ì´í„° ì¶”ì¶œ, AI ë¶„ì„, HTML ë³´ê³ ì„œ ìƒì„±ì„ í•œ ë²ˆì— ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    # ê¸°ë³¸ ì‚¬ìš©ë²• (sosreport ì••ì¶• íŒŒì¼ì„ ì…ë ¥)
    python3 ai_analyzer.py sosreport-archive.tar.xz --llm-url <URL> --model <MODEL> --api-token <TOKEN>
"""

import os
import sys
import json
import requests
import argparse
import time
import re
import tarfile
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, Optional, List
import html # HTML ì´ìŠ¤ì¼€ì´í”„ë¥¼ ìœ„í•´ ì¶”ê°€
import io
import base64
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- ê·¸ë˜í”„ ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---
# "pip install matplotlib" ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜ í•„ìš”
try:
    import matplotlib
    matplotlib.use('Agg') # GUI ë°±ì—”ë“œ ì—†ì´ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì„¤ì •
    import matplotlib.pyplot as plt
except ImportError:
    matplotlib = None
    plt = None

# --- ì›¹ ìŠ¤í¬ë ˆì´í•‘ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---
# "pip install beautifulsoup4 google-api-python-client" ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜ í•„ìš”
try:
    from bs4 import BeautifulSoup
    # Web Searchë¥¼ ìœ„í•œ google_searchëŠ” ì™¸ë¶€ì—ì„œ ì œê³µë˜ëŠ” ê²ƒìœ¼ë¡œ ê°€ì •í•©ë‹ˆë‹¤.
    # from google_search import search as google_search 
except ImportError:
    BeautifulSoup = None

class SosreportParser:
    """sosreport ì••ì¶• í•´ì œ í›„ ë””ë ‰í† ë¦¬ì—ì„œ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ JSON êµ¬ì¡°ë¡œ ë§Œë“­ë‹ˆë‹¤."""
    def __init__(self, extract_path: str):
        self.extract_path = Path(extract_path)
        subdirs = [d for d in self.extract_path.iterdir() if d.is_dir()]
        self.base_path = subdirs[0] if len(subdirs) == 1 else self.extract_path
        print(f"sosreport ë°ì´í„° ë¶„ì„ ê²½ë¡œ: {self.base_path}")

    def _read_file(self, possible_paths: List[str], default: str = 'N/A') -> str:
        """
        ì—¬ëŸ¬ ì˜ˆìƒ ê²½ë¡œ ì¤‘ íŒŒì¼ì„ ì°¾ì•„ ì•ˆì „í•˜ê²Œ ì½ì–´ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        for file_path in possible_paths:
            full_path = self.base_path / file_path
            if full_path.exists():
                try:
                    return full_path.read_text(encoding='utf-8', errors='ignore').strip()
                except Exception as e:
                    print(f"ê²½ê³ : '{file_path}' íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                    return "íŒŒì¼ ì½ê¸° ì˜¤ë¥˜"
        return default
    
    def _parse_installed_packages(self) -> List[str]:
        """installed-rpms íŒŒì¼ì—ì„œ 'íŒ¨í‚¤ì§€-ë²„ì „-ë¦´ë¦¬ì¦ˆ' ì „ì²´ ë¬¸ìì—´ì„ íŒŒì‹±í•©ë‹ˆë‹¤."""
        # [ìˆ˜ì •] ì‚¬ìš©ìê°€ ìš”ì²­í•œ ìƒˆë¡œìš´ rpm ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€ê²½
        rpm_content = self._read_file([
            'installed-rpms', 
            'sos_commands/rpm/sh_-c_rpm_--nodigest_-qa_--qf_NAME_-_VERSION_-_RELEASE_._ARCH_INSTALLTIME_date_awk_-F_printf_-59s_s_n_1_2_sort_-V', 
            'sos_commands/lvm2/vgdisplay_-vv_--config_global_metadata_read_only_1_--nolocking_--foreign', 
            'sos_commands/rpm/sh_-c_rpm_--nodigest_-qa_--qf_-59_NVRA_INSTALLTIME_date_sort_-V'
        ])

        if rpm_content == 'N/A' or not rpm_content.strip():
            print("âš ï¸ 'installed-rpms' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            return []
        
        packages = []
        # rpm ì¿¼ë¦¬ ê²°ê³¼ê°€ ë³µì¡í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì¼ë°˜ì ì¸ íŒ¨í‚¤ì§€ ì´ë¦„ í˜•ì‹ì„ ì¶”ì¶œí•˜ë„ë¡ ì •ê·œì‹ ì‚¬ìš©
        package_pattern = re.compile(r'^([a-zA-Z0-9_.+-]+-\d+.*)')
        for line in rpm_content.split('\n'):
            line = line.strip()
            if not line or line.startswith(('gpg-pubkey', 'warning:', 'error:')):
                continue
            
            match = package_pattern.match(line)
            if match:
                packages.append(match.group(1))
            else:
                # ê°„ë‹¨í•œ í˜•ì‹ (ì´ë¦„ë§Œ ìˆëŠ” ê²½ìš°)
                parts = line.split()
                if len(parts) > 0:
                    packages.append(parts[0])


        unique_packages = sorted(list(set(packages)))
        print(f"âœ… ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€(ë²„ì „ í¬í•¨) íŒŒì‹± ì™„ë£Œ: {len(unique_packages)}ê°œ")
        return unique_packages

    def _parse_system_details(self) -> Dict[str, Any]:
        """xsos ìŠ¤íƒ€ì¼ì˜ ìƒì„¸ ì‹œìŠ¤í…œ ì •ë³´ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        details = {}
        details['hostname'] = self._read_file(['hostname', 'sos_commands/general/hostname', 'proc/sys/kernel/hostname'])
        details['os_version'] = self._read_file(['etc/redhat-release'])
        uname_content = self._read_file(['uname', 'sos_commands/kernel/uname_-a'])
        details['kernel'] = uname_content.split('\n')[0]
        dmidecode_content = self._read_file(['dmidecode', 'sos_commands/hardware/dmidecode'])
        model_match = re.search(r'Product Name:\s*(.*)', dmidecode_content)
        details['system_model'] = model_match.group(1).strip() if model_match else 'N/A'
        lscpu_content = self._read_file(['lscpu', 'sos_commands/processor/lscpu'])
        cpu_model = re.search(r'Model name:\s+(.*)', lscpu_content)
        cpu_cores = re.search(r'^CPU\(s\):\s+(\d+)', lscpu_content, re.MULTILINE)
        details['cpu'] = f"{cpu_cores.group(1) if cpu_cores else 'N/A'} x {cpu_model.group(1).strip() if cpu_model else 'N/A'}"
        meminfo_content = self._read_file(['proc/meminfo'])
        mem_total = re.search(r'MemTotal:\s+(\d+)\s+kB', meminfo_content)
        details['memory'] = f"{int(mem_total.group(1)) / 1024 / 1024:.1f} GiB" if mem_total else 'N/A'
        details['uptime'] = self._read_file(['uptime', 'sos_commands/general/uptime', 'sos_commands/host/uptime'])
        
        last_boot_str = "N/A"
        proc_stat_content = self._read_file(['proc/stat'])
        btime_match = re.search(r'^btime\s+(\d+)', proc_stat_content, re.MULTILINE)
        if btime_match:
            try:
                epoch_time = int(btime_match.group(1))
                boot_datetime = datetime.fromtimestamp(epoch_time)
                timedatectl_content = self._read_file(['sos_commands/host/timedatectl_status'])
                tz_match = re.search(r'Time zone:\s+[\w/]+\s+\((.*?),', timedatectl_content)
                tz_abbr = tz_match.group(1) if tz_match else ""
                formatted_date = boot_datetime.strftime(f'%a %b %d %H:%M:%S {tz_abbr} %Y').strip()
                last_boot_str = f"{formatted_date} (epoch: {epoch_time})"
            except (ValueError, OSError) as e:
                print(f"ê²½ê³ : ë¶€íŒ… ì‹œê°„(epoch) ë³€í™˜ ì‹¤íŒ¨: {e}")
                last_boot_str = "Epoch ë³€í™˜ ì˜¤ë¥˜"
        if last_boot_str == "N/A" or "ì˜¤ë¥˜" in last_boot_str:
             last_boot_str = self._read_file(['sos_commands/boot/who_-b', 'sos_commands/startup/who_-b']).replace('system boot', '').strip()
        details['last_boot'] = last_boot_str
        
        return details

    def _parse_storage(self) -> List[Dict[str, str]]:
        """df -h ì¶œë ¥ì—ì„œ íŒŒì¼ ì‹œìŠ¤í…œ ì‚¬ìš©ëŸ‰ì„ íŒŒì‹±í•©ë‹ˆë‹¤."""
        df_content = self._read_file(['df', 'sos_commands/filesys/df_-alPh'])
        filesystems = []
        for line in df_content.split('\n')[1:]:
            parts = line.split()
            if len(parts) >= 6 and parts[0].startswith('/'):
                filesystems.append({'filesystem': parts[0], 'size': parts[1], 'used': parts[2], 'avail': parts[3], 'use%': parts[4], 'mounted_on': parts[5]})
        return filesystems

    def _parse_process_stats(self) -> Dict[str, Any]:
        """ps ëª…ë ¹ì–´ ì¶œë ¥ì—ì„œ í”„ë¡œì„¸ìŠ¤ ê´€ë ¨ í†µê³„ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        ps_content = self._read_file(['sos_commands/process/ps_auxwww', 'sos_commands/process/ps_auxwwwm', 'ps'])
        if ps_content == 'N/A':
            return {'total': 0, 'by_user': [], 'uninterruptible': [], 'zombie': [], 'top_cpu': [], 'top_mem': []}

        lines = ps_content.split('\n')
        header_found = False
        processes = []
        
        for line in lines:
            if re.match(r'USER\s+PID\s+%CPU', line):
                header_found = True
                continue
            if not header_found:
                continue

            parts = line.split(maxsplit=10)
            if len(parts) >= 11:
                try:
                    processes.append({
                        'user': parts[0], 'pid': parts[1], 'cpu%': float(parts[2]),
                        'mem%': float(parts[3]), 'vsz': int(parts[4]), 'rss': int(parts[5]),
                        'stat': parts[7], 'start': parts[8], 'time': parts[9], 'command': parts[10]
                    })
                except (ValueError, IndexError):
                    continue
        
        total_processes = len(processes)
        uninterruptible = [p for p in processes if 'D' in p['stat']]
        zombie = [p for p in processes if 'Z' in p['stat']]
        
        user_stats = {}
        for p in processes:
            user = p['user']
            if user not in user_stats:
                user_stats[user] = {'cpu%': 0.0, 'mem%': 0.0, 'rss': 0}
            user_stats[user]['cpu%'] += p['cpu%']
            user_stats[user]['mem%'] += p['mem%']
            user_stats[user]['rss'] += p['rss']
        
        top_users = sorted(user_stats.items(), key=lambda item: item[1]['cpu%'], reverse=True)[:5]
        
        formatted_top_users = []
        for user, stats in top_users:
            formatted_top_users.append({
                'user': user,
                'cpu%': f"{stats['cpu%']:.1f}%",
                'mem%': f"{stats['mem%']:.1f}%",
                'rss': f"{stats['rss'] / 1024 / 1024:.2f} GiB" if stats['rss'] > 1024*1024 else f"{stats['rss'] / 1024:.2f} MiB"
            })
        
        top_cpu = sorted(processes, key=lambda p: p['cpu%'], reverse=True)[:5]
        top_mem = sorted(processes, key=lambda p: p['rss'], reverse=True)[:5]

        print(f"âœ… í”„ë¡œì„¸ìŠ¤ í†µê³„ íŒŒì‹± ì™„ë£Œ: {total_processes}ê°œ í”„ë¡œì„¸ìŠ¤")
        return {
            'total': total_processes,
            'by_user': formatted_top_users,
            'uninterruptible': uninterruptible,
            'zombie': zombie,
            'top_cpu': top_cpu,
            'top_mem': top_mem
        }

    def _parse_failed_services(self) -> List[str]:
        """systemctl list-units ì¶œë ¥ì—ì„œ ì‹¤íŒ¨í•œ ì„œë¹„ìŠ¤ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        systemctl_content = self._read_file(['sos_commands/systemd/systemctl_list-units_--all'])
        failed_services = []
        for line in systemctl_content.split('\n'):
            if 'failed' in line:
                parts = line.strip().split()
                if len(parts) >= 4:
                    failed_services.append(f"{parts[0]} - {' '.join(parts[1:4])}")
        return failed_services

    def _parse_ip4_details(self) -> List[Dict[str, str]]:
        """ip addr ëª…ë ¹ì–´ ì¶œë ¥ì—ì„œ ìƒì„¸ ì¸í„°í˜ì´ìŠ¤ ì •ë³´ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        ip_addr_content = self._read_file(['sos_commands/networking/ip_addr', 'sos_commands/networking/ip_-d_address'])
        if ip_addr_content == 'N/A': return []
        
        interfaces = []
        blocks = re.split(r'^\d+:\s+', ip_addr_content, flags=re.MULTILINE)
        if not blocks[0].strip():
            blocks.pop(0)

        for block in blocks:
            if not block.strip(): continue
            iface_data = {}
            
            name_match = re.match(r'([\w.-]+):', block)
            if not name_match: continue
            iface_data['iface'] = name_match.group(1)

            mtu_match = re.search(r'mtu\s+(\d+)', block)
            iface_data['mtu'] = mtu_match.group(1) if mtu_match else '-'
            
            state_match = re.search(r'state\s+(\w+)', block)
            iface_data['state'] = state_match.group(1).lower() if state_match else 'unknown'
            
            master_match = re.search(r'master\s+([\w.-]+)', block)
            iface_data['master'] = master_match.group(1) if master_match else '-'

            mac_match = re.search(r'link/\w+\s+([\da-fA-F:]+)', block)
            iface_data['mac'] = mac_match.group(1) if mac_match else '-'

            ip_match = re.search(r'inet\s+([\d.]+/\d+)', block)
            iface_data['ipv4'] = ip_match.group(1) if ip_match else '-'
            
            interfaces.append(iface_data)
            
        return interfaces

    def _parse_network_details(self) -> Dict[str, Any]:
        """NETDEV, SOCKSTAT, BONDING, ETHTOOL ì •ë³´ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        details = {'netdev': [], 'sockstat': [], 'bonding': [], 'ethtool': {}}

        # NETDEV
        netdev_content = self._read_file(['proc/net/dev'])
        for line in netdev_content.split('\n')[2:]:
            if ':' not in line: continue
            iface, stats = line.split(':', 1)
            iface = iface.strip()
            stat_values = stats.split()
            if len(stat_values) == 16:
                details['netdev'].append({
                    'iface': iface,
                    'rx_bytes': int(stat_values[0]), 'rx_packets': int(stat_values[1]), 'rx_errs': int(stat_values[2]), 'rx_drop': int(stat_values[3]),
                    'rx_fifo': int(stat_values[4]), 'rx_frame': int(stat_values[5]), 'rx_compressed': int(stat_values[6]), 'rx_multicast': int(stat_values[7]),
                    'tx_bytes': int(stat_values[8]), 'tx_packets': int(stat_values[9]), 'tx_errs': int(stat_values[10]), 'tx_drop': int(stat_values[11]),
                    'tx_fifo': int(stat_values[12]), 'tx_colls': int(stat_values[13]), 'tx_carrier': int(stat_values[14]), 'tx_compressed': int(stat_values[15])
                })

        # SOCKSTAT
        sockstat_content = self._read_file(['proc/net/sockstat'])
        details['sockstat'] = sockstat_content.split('\n')

        # BONDING
        bonding_dir = self.base_path / 'proc/net/bonding'
        if bonding_dir.is_dir():
            for bond_file in bonding_dir.iterdir():
                bond_content = bond_file.read_text(encoding='utf-8', errors='ignore')
                bond_info = {'device': bond_file.name}
                mode_match = re.search(r'Bonding Mode:\s*(.*)', bond_content)
                if mode_match: bond_info['mode'] = mode_match.group(1).strip()
                slaves = re.findall(r'Slave Interface:\s*(\w+)', bond_content)
                bond_info['slaves'] = slaves
                details['bonding'].append(bond_info)
        
        # ETHTOOL
        ethtool_dir = self.base_path / 'sos_commands/networking'
        if ethtool_dir.is_dir():
            all_ifaces = [dev['iface'] for dev in details['netdev']]
            for iface_name in all_ifaces:
                details['ethtool'][iface_name] = {}
                
                content = self._read_file([f'sos_commands/networking/ethtool_{iface_name}'])
                link_match = re.search(r'Link detected:\s*(yes|no)', content)
                speed_match = re.search(r'Speed:\s*(.*)', content)
                driver_match = re.search(r'driver:\s*(.*)', content)
                fw_match = re.search(r'firmware-version:\s*(.*)', content)
                
                details['ethtool'][iface_name]['link'] = link_match.group(1) if link_match else 'N/A'
                details['ethtool'][iface_name]['speed'] = speed_match.group(1).strip() if speed_match else 'N/A'
                details['ethtool'][iface_name]['driver'] = driver_match.group(1).strip() if driver_match else 'N/A'
                details['ethtool'][iface_name]['firmware'] = fw_match.group(1).strip() if fw_match else 'N/A'

                content_s = self._read_file([f'sos_commands/networking/ethtool_-S_{iface_name}'])
                errors = {}
                for line in content_s.split('\n'):
                    match = re.search(r'\s*(\w+.*):\s*(\d+)', line)
                    if match and int(match.group(2)) > 0:
                        errors[match.group(1).strip()] = match.group(2)
                if errors:
                    details['ethtool'][iface_name]['errors'] = errors
        
        return details

    def _parse_routing_table(self) -> List[Dict[str, str]]:
        """ë¼ìš°íŒ… í…Œì´ë¸” ì •ë³´ë¥¼ íŒŒì‹±í•˜ê³  ë¶ˆí•„ìš”í•œ í•­ëª©ì„ í•„í„°ë§í•©ë‹ˆë‹¤."""
        routing_content = self._read_file(['sos_commands/networking/ip_route_show_table_all', 'sos_commands/networking/ip_route_show'])
        routes = []
        exclusion_keywords = ["broadcast", "local", "unreachable"]

        for line in routing_content.split('\n'):
            if not line.strip(): continue
            parts = line.split()
            
            if parts[0] in exclusion_keywords:
                continue

            route_info = {'destination': parts[0], 'gateway': '-', 'device': '-', 'source': '-'}
            
            try:
                if 'via' in parts:
                    route_info['gateway'] = parts[parts.index('via') + 1]
                if 'dev' in parts:
                    route_info['device'] = parts[parts.index('dev') + 1]
                if 'src' in parts:
                    route_info['source'] = parts[parts.index('src') + 1]
            except IndexError:
                continue

            if route_info['source'].startswith('127.'):
                continue
            
            if route_info['destination'].lower() != 'default' and route_info['source'] == '-':
                continue
            
            routes.append(route_info)
        return routes

    def _parse_sar_data(self) -> Dict[str, List[Dict[str, Any]]]:
        """sar ëª…ë ¹ì–´ ì¶œë ¥ ê²°ê³¼ì—ì„œ ì„±ëŠ¥ ë°ì´í„°ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        content = ""
        sa_dir = self.base_path / 'var/log/sa'
        if sa_dir.is_dir():
            sar_files = sorted([f for f in sa_dir.iterdir() if f.name.startswith('sar') and f.is_file()])
            if sar_files:
                for file_path in sar_files: content += file_path.read_text(encoding='utf-8', errors='ignore') + "\n"
        
        if not content.strip():
            content = self._read_file(['sos_commands/monitoring/sar_-A'])

        if not content.strip(): return {}
        print("sar ì„±ëŠ¥ ë°ì´í„° íŒŒì‹± ì¤‘...")
        performance_data = {'cpu': [], 'memory': [], 'network': []}

        cpu_section = re.search(r'(\d{2}:\d{2}:\d{2}\s+CPU\s+%user\s+%nice\s+%system\s+%iowait\s+%steal\s+%idle\n(?:.*\n)+?)\n\n', content, re.MULTILINE)
        if cpu_section:
            for line in cpu_section.group(1).strip().split('\n'):
                parts = line.split()
                if len(parts) >= 8 and parts[1] == 'all':
                    performance_data['cpu'].append({'timestamp': parts[0], 'user': float(parts[2]), 'system': float(parts[4]), 'idle': float(parts[7])})

        mem_section = re.search(r'(\d{2}:\d{2}:\d{2}\s+kbmemfree\s+kbmemused\s+%memused\s+kbbuffers\s+kbcached\s+kbcommit\s+%commit\n(?:.*\n)+?)\n\n', content, re.MULTILINE)
        if mem_section:
            for line in mem_section.group(1).strip().split('\n'):
                parts = line.split()
                if len(parts) >= 4 and parts[0].count(':') == 2:
                    performance_data['memory'].append({'timestamp': parts[0], 'memused_percent': float(parts[3])})

        net_section = re.search(r'(\d{2}:\d{2}:\d{2}\s+IFACE\s+rxpck/s\s+txpck/s\s+rxkB/s\s+txkB/s\s+rxcmp/s\s+txcmp/s\s+rxmcst/s\n(?:.*\n)+?)\n\n', content, re.MULTILINE)
        if net_section:
            net_agg = {}
            for line in net_section.group(1).strip().split('\n'):
                parts = line.split()
                if len(parts) >= 6 and parts[1] not in ('IFACE', 'lo'):
                    ts = parts[0]
                    if ts not in net_agg: net_agg[ts] = {'rxkB': 0.0, 'txkB': 0.0}
                    net_agg[ts]['rxkB'] += float(parts[4])
                    net_agg[ts]['txkB'] += float(parts[5])
            for ts, data in net_agg.items():
                performance_data['network'].append({'timestamp': ts, **data})

        print("âœ… sar ì„±ëŠ¥ ë°ì´í„° íŒŒì‹± ì™„ë£Œ.")
        return performance_data

    def parse(self) -> Dict[str, Any]:
        """ì£¼ìš” sosreport íŒŒì¼ë“¤ì„ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        print("sosreport ë°ì´í„° íŒŒì‹± ì‹œì‘...")
        system_info = self._parse_system_details()
        system_info['routing_table'] = self._parse_routing_table()

        data = {
            "system_info": system_info,
            "ip4_details": self._parse_ip4_details(),
            "network_details": self._parse_network_details(),
            "storage": self._parse_storage(),
            "process_stats": self._parse_process_stats(),
            "failed_services": self._parse_failed_services(),
            "performance_data": self._parse_sar_data(),
            "installed_packages": self._parse_installed_packages(),
            "analysis_timestamp": datetime.now().isoformat()
        }
        print("âœ… sosreport ë°ì´í„° íŒŒì‹± ì™„ë£Œ.")
        return data

class AIAnalyzer:
    def __init__(self, llm_url: str, model_name: Optional[str] = None, 
                 endpoint_path: str = "/v1/chat/completions",
                 api_token: Optional[str] = None,
                 timeout: int = 300,
                 output_dir: str = 'output'):
        """AI ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        match = re.search(r'https?://[^\s\)]+', llm_url)
        cleaned_url = match.group(0) if match else llm_url
        
        self.llm_url = cleaned_url.rstrip('/')
        self.model_name = model_name
        self.endpoint_path = endpoint_path
        self.completion_url = f"{self.llm_url}{self.endpoint_path}"
        self.api_token = api_token
        self.timeout = timeout
        self.session = requests.Session()
        self.output_dir = Path(output_dir)
        
        headers = {'Content-Type': 'application/json', 'Accept': 'application/json'}
        if self.api_token:
            headers['Authorization'] = f'Bearer {self.api_token}'
        self.session.headers.update(headers)

        print("AI ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"LLM ê¸°ë³¸ URL: {self.llm_url}")
        if self.model_name:
            print(f"ì‚¬ìš© ëª¨ë¸: {self.model_name}")

    def list_available_models(self):
        """ì„œë²„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•˜ê³  ì¶œë ¥í•©ë‹ˆë‹¤."""
        print(f"'{self.llm_url}' ì„œë²„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤...")
        models_url = f"{self.llm_url}/v1/models"
        try:
            response = self.session.get(models_url, timeout=20)
            if response.status_code != 200:
                print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: HTTP {response.status_code}, ë‚´ìš©: {response.text[:200]}")
                return

            models_data = response.json()
            if 'data' in models_data and models_data['data']:
                print("\n--- ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ---")
                for model in models_data['data']:
                    print(f"- {model.get('id')}")
                print("------------------------\n")
            else:
                print("âŒ ì‘ë‹µì—ì„œ ëª¨ë¸ ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except requests.exceptions.RequestException as e:
            print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def check_llm_service(self, max_retries: int = 3) -> bool:
        """LLM ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
        print("LLM ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì¤‘...")
        for attempt in range(max_retries):
            try:
                response = self.session.get(self.llm_url, timeout=10)
                if response.status_code in [200, 404, 401, 403]:
                    print(f"âœ… LLM ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ (ì‹œë„ {attempt + 1}/{max_retries})")
                    return True
            except requests.exceptions.RequestException as e:
                print(f"ì—°ê²° ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
            if attempt < max_retries - 1:
                time.sleep(5)
        print("âŒ 3ë²ˆ ì‹œë„ í›„ì—ë„ LLM ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return False

    def test_llm_connection(self) -> bool:
        """LLM ì—°ê²° í…ŒìŠ¤íŠ¸"""
        if not self.model_name:
            print("âš ï¸ ëª¨ë¸ ì´ë¦„ì´ ì§€ì •ë˜ì§€ ì•Šì•„ ì—°ê²° í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False
        print("LLM ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
        try:
            test_payload = {"model": self.model_name, "messages": [{"role": "user", "content": "Connection test. Reply with 'OK'."}], "max_tokens": 10}
            response = self.session.post(self.completion_url, json=test_payload, timeout=30)
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and result.get('choices'):
                    print(f"âœ… ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ: {result['choices'][0]['message']['content'].strip()}")
                    return True
            print(f"âŒ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: HTTP {response.status_code}, ë‚´ìš©: {response.text[:200]}")
            return False
        except Exception as e:
            print(f"âŒ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return False

    def perform_ai_analysis(self, prompt: str, is_news_request: bool = False) -> Any:
        """AI ë¶„ì„ ìˆ˜í–‰. ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ."""
        print("AI ë¶„ì„ ì‹œì‘...")
        try:
            payload = {
                "model": self.model_name,
                "messages": [
                    {"role": "system", "content": "You are a helpful assistant designed to output JSON."},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 16384, 
                "temperature": 0.1,
            }
            start_time = time.time()
            print(f"LLM API í˜¸ì¶œ ì¤‘... ({self.completion_url})")

            if is_news_request:
                llm_log_path = self.output_dir / "llm_security_news.log"
                with open(llm_log_path, 'a', encoding='utf-8') as f:
                    f.write("\n\n--- NEW PROMPT FOR SECURITY NEWS ---\n")
                    f.write(prompt)
                    f.write("\n\n--- LLM RESPONSE ---\n")
                print("\n--- LLMì—ê²Œ ë³´ë‚¸ ë³´ì•ˆ ë‰´ìŠ¤ í”„ë¡¬í”„íŠ¸ ---")
                print(prompt[:500] + "...")
                print("-------------------------------------\n")

            response = self.session.post(self.completion_url, json=payload, timeout=self.timeout)
            print(f"API ì‘ë‹µ ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ")

            if response.status_code != 200:
                raise ValueError(f"API í˜¸ì¶œ ì‹¤íŒ¨: HTTP {response.status_code}, ë‚´ìš©: {response.text[:500]}")
            
            result = response.json()
            if 'choices' not in result or not result['choices']:
                raise ValueError(f"API ì‘ë‹µì— 'choices' í‚¤ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì‘ë‹µ: {result}")

            ai_response = result['choices'][0]['message']['content']
            
            if is_news_request:
                with open(llm_log_path, 'a', encoding='utf-8') as f:
                    f.write(ai_response)

            return self._parse_ai_response(ai_response)
        except (requests.exceptions.RequestException, ValueError) as e:
            raise Exception(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def create_analysis_prompt(self, sosreport_data: Dict[str, Any]) -> str:
        """AI ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        print("AI ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        
        data_str = json.dumps({
            "system_info": sosreport_data.get("system_info"),
            "storage": sosreport_data.get("storage"),
            "failed_services": sosreport_data.get("failed_services"),
            "process_stats_summary": {
                "total": sosreport_data.get("process_stats", {}).get("total"),
                "zombie_count": len(sosreport_data.get("process_stats", {}).get("zombie", [])),
            }
        }, indent=2, ensure_ascii=False)

        prompt = f"""ë‹¹ì‹ ì€ Red Hat Enterprise Linux ì‹œìŠ¤í…œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ sosreport ë¶„ì„ ë°ì´í„°ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê²€í† í•˜ê³  ì „ë¬¸ì ì¸ ì§„ë‹¨ì„ ì œê³µí•´ì£¼ì„¸ìš”.

## ë¶„ì„ ë°ì´í„°
```json
{data_str}
```

## ë¶„ì„ ìš”ì²­
ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ JSON í˜•ì‹ì— ë§ì¶° ì¢…í•©ì ì¸ ì‹œìŠ¤í…œ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.

```json
{{
  "system_status": "ì •ìƒ|ì£¼ì˜|ìœ„í—˜",
  "overall_health_score": 100,
  "critical_issues": ["ë°œê²¬ëœ ì‹¬ê°í•œ ë¬¸ì œë“¤ì˜ êµ¬ì²´ì ì¸ ì„¤ëª…"],
  "warnings": ["ì£¼ì˜ê°€ í•„ìš”í•œ ì‚¬í•­ë“¤"],
  "recommendations": [
    {{
      "priority": "ë†’ìŒ|ì¤‘ê°„|ë‚®ìŒ",
      "category": "ì„±ëŠ¥|ë³´ì•ˆ|ì•ˆì •ì„±|ìœ ì§€ë³´ìˆ˜",
      "issue": "ë¬¸ì œì  ì„¤ëª…",
      "solution": "êµ¬ì²´ì ì¸ í•´ê²° ë°©ì•ˆ"
    }}
  ],
  "summary": "ì „ì²´ì ì¸ ì‹œìŠ¤í…œ ìƒíƒœì™€ ì£¼ìš” ê¶Œì¥ì‚¬í•­ì— ëŒ€í•œ ì¢…í•© ìš”ì•½"
}}
```

**ì¤‘ìš”**: ë‹¹ì‹ ì˜ ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ„ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ ì—†ì´, `{{`ë¡œ ì‹œì‘í•´ì„œ `}}`ë¡œ ëë‚˜ëŠ” ìˆœìˆ˜í•œ JSON ê°ì²´ë§Œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.
"""
        return prompt

    def _parse_ai_response(self, ai_response: str) -> Any:
        """AI ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ ë° íŒŒì‹±. ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ."""
        print("AI ì‘ë‹µ íŒŒì‹± ì¤‘...")
        
        if not ai_response or not ai_response.strip():
            raise ValueError("AI ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

        refusal_patterns = [
            "i'm sorry", "i cannot", "i can't", "i am unable", 
            "ì£„ì†¡í•©ë‹ˆë‹¤", "í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        ]
        if any(pattern in ai_response.lower() for pattern in refusal_patterns):
            raise ValueError(f"LLMì´ ìš”ì²­ ì²˜ë¦¬ë¥¼ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤. (ì‘ë‹µ: '{ai_response.strip()}')")

        try:
            cleaned_response = re.sub(r'^```(json)?\s*|\s*```$', '', ai_response.strip())
            start = cleaned_response.find('{')
            end = cleaned_response.rfind('}')
            
            if start == -1 or end == -1 or end < start:
                raise ValueError("ì‘ë‹µì—ì„œ ìœ íš¨í•œ JSON ê°ì²´({{ ... }})ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            json_str = cleaned_response[start:end+1]
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            error_message = f"AI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}.\n--- ì›ë³¸ ì‘ë‹µ ---\n{ai_response}\n----------------"
            print(error_message)
            raise ValueError(error_message)
        except ValueError as e:
            error_message = f"AI ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}.\n--- ì›ë³¸ ì‘ë‹µ ---\n{ai_response}\n----------------"
            print(error_message)
            raise ValueError(error_message)

    def fetch_web_search_cves(self, installed_package_names: set) -> set:
        """Web Searchë¥¼ í†µí•´ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ì™€ ê´€ë ¨ëœ ìµœì‹  CVE ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        print("Web Searchë¥¼ í†µí•´ ìµœì‹  CVE ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        web_cves = set()
        cve_pattern = re.compile(r'CVE-\d{4}-\d{4,7}', re.IGNORECASE)
        
        # ì‹œìŠ¤í…œì˜ í•µì‹¬ íŒ¨í‚¤ì§€ë‚˜ ìì£¼ ì‚¬ìš©ë˜ëŠ” íŒ¨í‚¤ì§€ë¥¼ ìš°ì„  ê²€ìƒ‰
        priority_packages = ['kernel', 'openssl', 'glibc', 'httpd', 'openssh', 'systemd', 'qemu-kvm', 'libvirt', 'java']
        search_packages = [pkg for pkg in priority_packages if pkg in installed_package_names]
        # ë§Œì•½ ìš°ì„ ìˆœìœ„ íŒ¨í‚¤ì§€ê°€ ì—†ë‹¤ë©´, ì „ì²´ íŒ¨í‚¤ì§€ ì¤‘ ì¼ë¶€ë¥¼ ì‚¬ìš©
        if not search_packages:
            search_packages = list(installed_package_names)[:5]

        queries = []
        for pkg in search_packages:
            queries.append(f'"{pkg}" Red Hat Enterprise Linux vulnerability CVE')
            queries.append(f'"{pkg}" RHEL ë³´ì•ˆ ì·¨ì•½ì  CVE')

        print(f"Web Search ì¿¼ë¦¬: {queries}")

        try:
            # google_searchê°€ ì™¸ë¶€ì—ì„œ ì œê³µë˜ëŠ” í•¨ìˆ˜ë¼ê³  ê°€ì •
            search_results = google_search.search(queries=queries)
            for result_set in search_results:
                if result_set.results:
                    for result in result_set.results:
                        if result.snippet:
                            found = cve_pattern.findall(result.snippet)
                            for cve in found:
                                web_cves.add(cve.upper())
            print(f"Web Searchë¥¼ í†µí•´ {len(web_cves)}ê°œì˜ ê³ ìœ  CVEë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤: {web_cves if web_cves else 'ì—†ìŒ'}")
        except Exception as e:
            print(f"âš ï¸ Web Search ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        return web_cves

    def fetch_security_news(self, sos_data: Dict[str, Any]) -> List[Dict[str, str]]:
        """
        Red Hat APIì™€ Web Searchë¥¼ í†µí•´ ì‹œìŠ¤í…œì— ê°€ì¥ ì¤‘ìš”í•œ CVEë¥¼ ì„ ë³„í•©ë‹ˆë‹¤.
        """
        print("ìµœì‹  RHEL ë³´ì•ˆ ë‰´ìŠ¤ ì¡°íšŒ ë° Web Search ì •ë³´ì™€ êµì°¨ ë¶„ì„ ì‹œì‘...")
        
        installed_packages_db = set(sos_data.get("installed_packages", []))
        if not installed_packages_db:
            reason = "sosreportì— ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ì •ë³´(installed-rpms)ê°€ ì—†ì–´ CVE ì—°ê´€ì„±ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            print(f"âš ï¸ {reason}")
            return [{"reason": reason}]

        try:
            installed_package_names_only = set(re.sub(r'-[\d.:].*', '', pkg) for pkg in installed_packages_db)
            
            # [ìˆ˜ì •] Web Search ê¸°ëŠ¥ í˜¸ì¶œ
            web_priority_cves = self.fetch_web_search_cves(installed_package_names_only)

            kernel_version = sos_data.get("system_info", {}).get("kernel", "N/A")

            print(f"ë¶„ì„ ëŒ€ìƒ ì‹œìŠ¤í…œ ì»¤ë„ ë²„ì „: {kernel_version}")
            print(f"ë¶„ì„ ëŒ€ìƒ ì‹œìŠ¤í…œì˜ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ {len(installed_packages_db)}ê°œë¥¼ DBí™”í•˜ì—¬ ì°¸ê³ í•©ë‹ˆë‹¤.")

            api_url = "https://access.redhat.com/hydra/rest/securitydata/cve.json"
            print(f"Red Hat CVE API í˜¸ì¶œ: {api_url}")
            response = requests.get(api_url, timeout=120)
            if response.status_code != 200:
                print(f"âš ï¸ Red Hat CVE API ì¡°íšŒ ì‹¤íŒ¨ (HTTP {response.status_code})")
                return [{"reason": f"Red Hat CVE API ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ (HTTP {response.status_code})."}]

            all_cves = response.json()
            print(f"ì´ {len(all_cves)}ê°œì˜ CVE ë°ì´í„°ë¥¼ Red Hatì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
            
            now = datetime.now()
            start_date = now - timedelta(days=180)
            
            system_relevant_cves = []
            for cve in all_cves:
                public_date_str = cve.get('public_date')
                if not public_date_str: continue
                
                try:
                    cve_date = datetime.fromisoformat(public_date_str.replace('Z', '+00:00')).replace(tzinfo=None)
                except ValueError:
                    continue

                if not (start_date <= cve_date <= now and isinstance(cve.get('severity'), str) and cve.get('severity').lower() in ["critical", "important"]):
                    continue
                
                cve_affected_packages = cve.get('affected_packages', [])
                if any(re.match(r'^([a-zA-Z0-9_.+-]+)-', pkg_str) and re.match(r'^([a-zA-Z0-9_.+-]+)-', pkg_str).group(1) in installed_package_names_only for pkg_str in cve_affected_packages):
                    system_relevant_cves.append(cve)

            if not system_relevant_cves:
                reason = "ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ì£¼ëŠ” ìµœì‹  ë³´ì•ˆ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
                print(reason)
                return [{"reason": reason}]

            print(f"ì‹œìŠ¤í…œ ê´€ë ¨ CVE {len(system_relevant_cves)}ê°œë¥¼ 1ì°¨ ì„ ë³„í–ˆìŠµë‹ˆë‹¤.")

            top_priority_cves = []
            normal_priority_cves = []
            for cve in system_relevant_cves:
                if cve.get('CVE') in web_priority_cves:
                    cve['priority_reason'] = "ìµœì‹  ì›¹ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì–¸ê¸‰ëœ, ì‹œìŠ¤í…œì— ì§ì ‘ ì˜í–¥ì„ ì£¼ëŠ” ì·¨ì•½ì "
                    top_priority_cves.append(cve)
                else:
                    normal_priority_cves.append(cve)
            
            analysis_target_cves = top_priority_cves + normal_priority_cves
            print(f"ìš°ì„ ìˆœìœ„ ì •ë ¬ í›„: ì›¹ ê²€ìƒ‰ ì–¸ê¸‰ CVE {len(top_priority_cves)}ê°œ, ê¸°íƒ€ ì‹œìŠ¤í…œ ê´€ë ¨ CVE {len(normal_priority_cves)}ê°œ")

            cve_identifiers_with_priority = []
            for cve in analysis_target_cves:
                if 'priority_reason' in cve:
                    cve_identifiers_with_priority.append(f"{cve['CVE']} (ìµœìš°ì„ )")
                else:
                    cve_identifiers_with_priority.append(cve['CVE'])

            packages_str = "\n- ".join(list(installed_packages_db)[:50]) + ("..." if len(installed_packages_db) > 50 else "")

            selection_prompt = f"""
[ì‹œìŠ¤í…œ ì•ˆë‚´]
ë‹¹ì‹ ì€ Red Hat Enterprise Linux(RHEL)ë¥¼ ì „ë¬¸ìœ¼ë¡œ ë‹¤ë£¨ëŠ” 'ì‹œë‹ˆì–´ ë³´ì•ˆ ìœ„í˜‘ ë¶„ì„ê°€'ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ RHEL ê´€ë ¨ ë³´ì•ˆ ì·¨ì•½ì  ëª©ë¡ì„ ë¶„ì„í•˜ì—¬, íŠ¹ì • ì‹œìŠ¤í…œì— ê°€ì¥ ì‹œê¸‰í•˜ê³  ì¤‘ìš”í•œ Top 10ì„ ì„ ë³„í•˜ê³ , ê·¸ ì„ ë³„ ì´ìœ ë¥¼ ëª…í™•íˆ ê¸°ë¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ì„ ë³„ ê³¼ì •ì—ì„œ í•„ìš”í•˜ë‹¤ë©´ Web Search ë¥¼ í™œì„±í™”í•˜ì—¬ ê²€ìƒ‰ì„ ì§„í–‰í•©ë‹ˆë‹¤. 

[ë¶„ì„ ëŒ€ìƒ ì‹œìŠ¤í…œ ì •ë³´]
- **ì»¤ë„ ë²„ì „:** {kernel_version}
- **ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ëª©ë¡ (ì¼ë¶€):**
- {packages_str}

[ì„ ë³„ ê¸°ì¤€]
1.  **ì›¹ ë™í–¥ (ìµœìš°ì„ ):** ëª©ë¡ì—ì„œ `(ìµœìš°ì„ )`ìœ¼ë¡œ í‘œì‹œëœ CVEëŠ” ì‹œìŠ¤í…œì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ì£¼ë©´ì„œ ìµœì‹  ì›¹ ê²€ìƒ‰ì—ì„œë„ ì–¸ê¸‰ëœ ì‹œê¸‰í•œ ì·¨ì•½ì ì´ë¯€ë¡œ ë°˜ë“œì‹œ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.
2.  **ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—°ê´€ì„±:** ì£¼ì–´ì§„ ëª©ë¡ì˜ ëª¨ë“  CVEëŠ” ì´ë¯¸ ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ì™€ ì—°ê´€ì„±ì´ í™•ì¸ëœ ìƒíƒœì…ë‹ˆë‹¤.
3.  **ì˜í–¥ë°›ëŠ” í•µì‹¬ ì»´í¬ë„ŒíŠ¸:** `kernel`, `glibc`, `openssl`, `openssh`, `systemd` ë“± RHEL ì‹œìŠ¤í…œì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ì— ì˜í–¥ì„ ì£¼ëŠ” ì·¨ì•½ì ì„ ìš°ì„ ì ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤.
4.  **ì‹¤ì œ ê³µê²© ê°€ëŠ¥ì„±(Exploitability):** ê³µê°œëœ ê³µê²© ì½”ë“œê°€ ìˆê±°ë‚˜, ì‹¤ì œ ê³µê²©(In-the-wild)ì— ì‚¬ìš©ëœ ì‚¬ë¡€ê°€ ìˆëŠ” ì·¨ì•½ì ì„ ìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•©ë‹ˆë‹¤.

[ì…ë ¥ ë°ì´í„°]
ë¶„ì„ ëŒ€ìƒ CVE ëª©ë¡ (ëª¨ë‘ ì‹œìŠ¤í…œ ê´€ë ¨ì„±ì´ ìˆìœ¼ë©°, ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬ë¨): {', '.join(cve_identifiers_with_priority)}

[ì¶œë ¥ ì§€ì‹œ]
ìœ„ ì„ ë³„ ê¸°ì¤€ì„ ì¢…í•©ì ìœ¼ë¡œ ì ìš©í•˜ì—¬ ì„ ì •í•œ Top 10 CVEì— ëŒ€í•œ ì •ë³´ë¥¼ ì•„ë˜ JSON í˜•ì‹ì— ë§ì¶° **ì˜¤ì§ JSON ê°ì²´ë§Œ** ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
- `cve_id`: **ë°˜ë“œì‹œ [ì…ë ¥ ë°ì´í„°]ì— ì¡´ì¬í•˜ëŠ” CVE ID ì¤‘ì—ì„œë§Œ** ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.
- `selection_reason`: ì™œ ì´ CVEë¥¼ ì„ íƒí–ˆëŠ”ì§€ ì„ ë³„ ê¸°ì¤€(íŠ¹íˆ ì›¹ ë™í–¥ ë° ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—°ê´€ì„±)ì— ê·¼ê±°í•˜ì—¬ **í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ** ê¸°ìˆ í•´ì•¼ í•©ë‹ˆë‹¤.

```json
{{
  "cve_selection": [
    {{
      "cve_id": "CVE-XXXX-XXXX",
      "selection_reason": "ì´ CVEë¥¼ ì„ ë³„í•œ êµ¬ì²´ì ì¸ ì´ìœ "
    }}
  ]
}}
```
"""
            
            selection_result = self.perform_ai_analysis(selection_prompt, is_news_request=True)
            
            if not (isinstance(selection_result, dict) and 'cve_selection' in selection_result and selection_result['cve_selection']):
                print("âš ï¸ LLMì´ ì¤‘ìš” CVEë¥¼ ì„ ì •í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return [{"reason": "AIê°€ ë¶„ì„ ëŒ€ìƒ CVE ëª©ë¡ì—ì„œ ì¤‘ìš” CVEë¥¼ ì„ ì •í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}]

            llm_log_path = self.output_dir / "llm_security_news.log"
            selected_cves_from_llm = selection_result['cve_selection']
            
            original_cves_map = {cve['CVE']: cve for cve in analysis_target_cves}
            
            top_cves_data = []
            with open(llm_log_path, 'a', encoding='utf-8') as f:
                f.write("\n\n--- CVE SELECTION & VALIDATION ---\n")
                for item in selected_cves_from_llm:
                    cve_id = item.get('cve_id')
                    reason = item.get('selection_reason', 'No reason provided.')
                    
                    if cve_id and cve_id in original_cves_map:
                        log_entry = f"- [VALID] {cve_id}: {reason}\n"
                        f.write(log_entry)
                        print(f"ğŸ“ ë¡œê·¸ ê¸°ë¡ (ìœ íš¨): {cve_id} ì„ ë³„ ì´ìœ ")
                        top_cves_data.append(original_cves_map[cve_id])
                    else:
                        log_entry = f"- [INVALID/HALLUCINATED] ID: {cve_id}, Reason: {reason}\n"
                        f.write(log_entry)
                        print(f"âš ï¸ ê²½ê³ : AIê°€ ìƒì„±í•œ ìœ íš¨í•˜ì§€ ì•Šì€ CVE ID({cve_id})ë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤.")

            if not top_cves_data:
                print("âš ï¸ AIê°€ ì„ ì •í•œ ìœ íš¨í•œ CVEê°€ ì—†ìŠµë‹ˆë‹¤.")
                return [{"reason": "AIê°€ ìœ íš¨í•œ CVEë¥¼ ì„ ì •í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}]

            processing_data = [{"cve_id": cve['CVE'], "description": cve.get('bugzilla_description', 'ìš”ì•½ ì •ë³´ ì—†ìŒ')} for cve in top_cves_data]

            processing_prompt = f"""
[ì‹œìŠ¤í…œ ì•ˆë‚´]
ë‹¹ì‹ ì€ ì „ë¬¸ ê¸°ìˆ  ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ JSON ë°ì´í„°ì— í¬í•¨ëœ ê° CVEì˜ 'description'ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì‹­ì‹œì˜¤.

[ì…ë ¥ ë°ì´í„°]
```json
{json.dumps(processing_data, indent=2, ensure_ascii=False)}
```

[ì¶œë ¥ ì§€ì‹œ]
ì•„ë˜ JSON í˜•ì‹ì— ë§ì¶°, ë²ˆì—­ëœ ê²°ê³¼ë¥¼ **ì˜¤ì§ JSON ê°ì²´ë§Œ** ì¶œë ¥í•˜ì‹­ì‹œì˜¤.

```json
{{
  "processed_cves": [
    {{
      "cve_id": "CVE-XXXX-XXXX",
      "translated_description": "ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­ëœ ê¸°ìˆ  ìš”ì•½"
    }}
  ]
}}
```
"""

            processed_result = self.perform_ai_analysis(processing_prompt, is_news_request=True)

            final_cves = []
            if isinstance(processed_result, dict) and 'processed_cves' in processed_result:
                processed_map = {item['cve_id']: item for item in processed_result['processed_cves']}
                for cve_data in top_cves_data:
                    cve_id = cve_data['CVE']
                    if cve_id in processed_map:
                        processed_info = processed_map[cve_id]
                        cve_date_str = cve_data.get('public_date', '')
                        if cve_date_str:
                            try:
                                cve_data['public_date'] = datetime.fromisoformat(cve_date_str.replace('Z', '+00:00')).strftime('%y/%m/%d')
                            except ValueError:
                                pass
                        
                        cve_data['bugzilla_description'] = processed_info.get('translated_description', cve_data['bugzilla_description'])
                        final_cves.append(cve_data)
                        print(f"âœ… ë³´ì•ˆ ë‰´ìŠ¤ ì²˜ë¦¬ ì™„ë£Œ: {cve_id}")
            else:
                print("âš ï¸ LLMì˜ ë²ˆì—­ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ë¡œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                return top_cves_data

            print("âœ… ë³´ì•ˆ ë‰´ìŠ¤ ì¡°íšŒ ë° ì²˜ë¦¬ ì™„ë£Œ.")
            return final_cves

        except Exception as e:
            print(f"âŒ ë³´ì•ˆ ë‰´ìŠ¤ ì¡°íšŒ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return [{"reason": f"ë³´ì•ˆ ë‰´ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"}]

    def create_performance_graphs(self, perf_data: Dict[str, List[Dict[str, Any]]]) -> Dict[str, str]:
        """ì„±ëŠ¥ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê³  base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not plt:
            print("âš ï¸ ê·¸ë˜í”„ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤. 'matplotlib' ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.")
            return {}

        print("ì„±ëŠ¥ ê·¸ë˜í”„ ìƒì„± ì¤‘...")
        graphs = {}
        
        if perf_data.get('cpu'):
            cpu_data = perf_data['cpu']
            timestamps = [d['timestamp'] for d in cpu_data]
            user = [d['user'] for d in cpu_data]
            system = [d['system'] for d in cpu_data]
            idle = [d['idle'] for d in cpu_data]
            
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.stackplot(timestamps, user, system, idle, labels=['User %', 'System %', 'Idle %'], colors=['#007bff', '#ffc107', '#28a745'])
            ax.set_title('CPU Usage (%)')
            ax.legend(loc='upper left')
            plt.tight_layout()
            
            buf = io.BytesIO()
            fig.savefig(buf, format='png')
            graphs['cpu_graph'] = base64.b64encode(buf.getvalue()).decode('utf-8')
            plt.close(fig)

        if perf_data.get('memory'):
            mem_data = perf_data['memory']
            timestamps = [d['timestamp'] for d in mem_data]
            mem_used = [d['memused_percent'] for d in mem_data]
            
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.plot(timestamps, mem_used, label='Memory Used %', color='#dc3545')
            ax.set_title('Memory Usage (%)')
            ax.legend(loc='upper left')
            plt.tight_layout()

            buf = io.BytesIO()
            fig.savefig(buf, format='png')
            graphs['memory_graph'] = base64.b64encode(buf.getvalue()).decode('utf-8')
            plt.close(fig)

        if perf_data.get('network'):
            net_data = perf_data['network']
            timestamps = [d['timestamp'] for d in net_data]
            rxkB = [d['rxkB'] for d in net_data]
            txkB = [d['txkB'] for d in net_data]

            fig, ax = plt.subplots(figsize=(10, 5))
            ax.plot(timestamps, rxkB, label='Received (kB/s)', color='#17a2b8')
            ax.plot(timestamps, txkB, label='Transmitted (kB/s)', color='#6f42c1')
            ax.set_title('Network Traffic (kB/s)')
            ax.legend(loc='upper left')
            plt.tight_layout()

            buf = io.BytesIO()
            fig.savefig(buf, format='png')
            graphs['network_graph'] = base64.b64encode(buf.getvalue()).decode('utf-8')
            plt.close(fig)

        print("âœ… ì„±ëŠ¥ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ.")
        return graphs

    def create_html_report(self, analysis_result: Dict[str, Any], sos_data: Dict[str, Any], graphs: Dict[str, str], output_dir: str, original_file: str) -> str:
        """ë¶„ì„ ê²°ê³¼ì™€ ê·¸ë˜í”„ë¥¼ ë°”íƒ•ìœ¼ë¡œ HTML ë³´ê³ ì„œ ìƒì„±"""
        print("HTML ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        base_name = Path(original_file).stem.replace('.tar', '')
        report_file = Path(output_dir) / f"{base_name}_report.html"

        status = html.escape(analysis_result.get('system_status', 'N/A'))
        score = analysis_result.get('overall_health_score', 'N/A')
        summary = html.escape(analysis_result.get('summary', 'ì •ë³´ ì—†ìŒ')).replace('\n', '<br>')
        critical_issues = analysis_result.get('critical_issues', [])
        warnings = analysis_result.get('warnings', [])
        recommendations = analysis_result.get('recommendations', [])
        
        system_info = sos_data.get('system_info', {})
        ip4_details = sos_data.get('ip4_details', [])
        network_details = sos_data.get('network_details', {})
        storage_info = sos_data.get('storage', [])
        process_stats = sos_data.get('process_stats', {})
        failed_services = sos_data.get('failed_services', [])
        security_news = sos_data.get('security_news', [])

        status_colors = {"ì •ìƒ": "#28a745", "ì£¼ì˜": "#ffc107", "ìœ„í—˜": "#dc3545"}
        status_color = status_colors.get(status, "#6c757d")

        ip4_details_rows = ""
        if not ip4_details:
            ip4_details_rows = "<tr><td colspan='6' style='text-align:center;'>ë°ì´í„° ì—†ìŒ</td></tr>"
        else:
            for item in ip4_details:
                state_val = item.get('state', 'unknown').lower()
                if 'up' in state_val:
                    state_html = '<td style="color: green; font-weight: bold;">ğŸ”› UP</td>'
                elif 'down' in state_val:
                    state_html = '<td style="color: grey;">ğŸ“´ DOWN</td>'
                else:
                    state_html = f"<td>â“ {html.escape(state_val.upper())}</td>"
                
                ip4_details_rows += f"""
                    <tr>
                        <td>{html.escape(item.get('iface', 'N/A'))}</td>
                        <td>{html.escape(item.get('master', 'N/A'))}</td>
                        <td>{html.escape(item.get('mac', 'N/A'))}</td>
                        <td>{html.escape(item.get('mtu', 'N/A'))}</td>
                        {state_html}
                        <td>{html.escape(item.get('ipv4', 'N/A'))}</td>
                    </tr>
                """

        def create_table_rows(data_list, headers):
            rows = ""
            if not data_list:
                return f"<tr><td colspan='{len(headers)}' style='text-align:center;'>ë°ì´í„° ì—†ìŒ</td></tr>"
            
            if isinstance(data_list, list) and len(data_list) == 1 and 'reason' in data_list[0]:
                reason_text = html.escape(data_list[0]['reason'])
                return f"<tr><td colspan='{len(headers)}' style='text-align:center;'>{reason_text}</td></tr>"

            for item in data_list:
                rows += "<tr>"
                for header in headers:
                    if header == 'CVE' and isinstance(item.get(header), str):
                        cve_id = html.escape(item.get(header))
                        rows += f'<td><a href="https://access.redhat.com/security/cve/{cve_id}" target="_blank">{cve_id}</a></td>'
                    else:
                        rows += f"<td>{html.escape(str(item.get(header, 'N/A')))}</td>"
                rows += "</tr>"
            return rows

        graph_html = ""
        if graphs:
            graph_html += '<div class="section"><h2>ğŸ“Š ì„±ëŠ¥ ë¶„ì„ ê·¸ë˜í”„</h2>'
            if 'cpu_graph' in graphs: graph_html += f'<h3>CPU ì‚¬ìš©ë¥ </h3><img src="data:image/png;base64,{graphs["cpu_graph"]}" alt="CPU Graph" style="width:100%;">'
            if 'memory_graph' in graphs: graph_html += f'<h3>ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ </h3><img src="data:image/png;base64,{graphs["memory_graph"]}" alt="Memory Graph" style="width:100%;">'
            if 'network_graph' in graphs: graph_html += f'<h3>ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½</h3><img src="data:image/png;base64,{graphs["network_graph"]}" alt="Network Graph" style="width:100%;">'
            graph_html += '</div>'
        
        netdev_rx_rows = ""
        netdev_tx_rows = ""
        netdev_data = network_details.get('netdev', [])
        for dev in netdev_data:
            rx_packets = dev.get('rx_packets', 0)
            rx_drop = dev.get('rx_drop', 0)
            rx_multicast = dev.get('rx_multicast', 0)
            rx_drop_pct = f"({int(rx_drop * 100 / rx_packets)}%)" if rx_packets > 0 else ""
            rx_multicast_pct = f"({int(rx_multicast * 100 / rx_packets)}%)" if rx_packets > 0 else ""
            netdev_rx_rows += f"<tr><td>{html.escape(dev['iface'])}</td><td>{dev['rx_bytes']:,}</td><td>{dev['rx_packets']:,}</td><td>{dev['rx_errs']}</td><td>{dev['rx_drop']} {rx_drop_pct}</td><td>{dev['rx_multicast']} {rx_multicast_pct}</td></tr>"
            netdev_tx_rows += f"<tr><td>{html.escape(dev['iface'])}</td><td>{dev['tx_bytes']:,}</td><td>{dev['tx_packets']:,}</td><td>{dev['tx_errs']}</td><td>{dev['tx_drop']}</td><td>{dev['tx_colls']}</td><td>{dev['tx_carrier']}</td></tr>"

        ethtool_rows = ""
        ethtool_data = network_details.get('ethtool', {})
        for iface, data in ethtool_data.items():
            ethtool_rows += f"<tr><td>{html.escape(iface)}</td><td>{html.escape(data.get('link', 'N/A'))}</td><td>{html.escape(data.get('speed', 'N/A'))}</td><td>{html.escape(data.get('driver', 'N/A'))}</td><td>{html.escape(data.get('firmware', 'N/A'))}</td></tr>"

        html_template = f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI ë¶„ì„ ë³´ê³ ì„œ</title>
    <style>
        @import url('https://cdn.jsdelivr.net/gh/projectnoonnu/noonfonts_six@1.2/S-CoreDream.css');
        body {{ font-family: 'S-CoreDream', 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background-color: #f4f7f9; color: #333; margin: 0; padding: 20px; }}
        .container {{ max-width: 900px; margin: auto; background: #fff; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); overflow: hidden; }}
        header {{ background-color: #007bff; color: white; padding: 20px; text-align: center; }}
        header h1 {{ margin: 0; font-size: 24px; }}
        .content {{ padding: 20px; }}
        .section {{ margin-bottom: 20px; }}
        .section h2 {{ border-bottom: 2px solid #007bff; padding-bottom: 10px; margin-bottom: 15px; color: #007bff; }}
        .info-table, .data-table {{ width: 100%; border-collapse: collapse; margin-bottom: 20px; }}
        .info-table th, .info-table td, .data-table th, .data-table td {{ border: 1px solid #ddd; padding: 10px; text-align: left; word-break: break-all; }}
        .info-table th {{ background-color: #f2f2f2; width: 25%; font-weight: bold; }}
        .data-table th {{ background-color: #f2f2f2; font-weight: bold; }}
        .issue-list li {{ background: #fff3cd; border-left: 4px solid #ffc107; margin-bottom: 10px; padding: 10px; list-style-type: none; }}
        .critical-list li {{ background: #f8d7da; border-left-color: #dc3545; }}
        .ai-summary-card {{ background-color: #e9ecef; padding: 20px; border-radius: 8px; }}
        .ai-status {{ font-size: 1.5em; font-weight: bold; color: {status_color}; }}
        footer {{ text-align: center; padding: 15px; font-size: 12px; color: #888; background-color: #f4f7f9; }}
    </style>
</head>
<body>
    <div class="container">
        <header><h1>S-Core System Report</h1></header>
        <div class="content">
            <div class="section">
                <h2>â„¹ï¸ ì‹œìŠ¤í…œ ìš”ì•½</h2>
                <table class="info-table">
                    <tr><th>Hostname</th><td>{html.escape(system_info.get('hostname', 'N/A'))}</td></tr>
                    <tr><th>OS Version</th><td>{html.escape(system_info.get('os_version', 'N/A'))}</td></tr>
                    <tr><th>Kernel</th><td>{html.escape(system_info.get('kernel', 'N/A'))}</td></tr>
                    <tr><th>System Model</th><td>{html.escape(system_info.get('system_model', 'N/A'))}</td></tr>
                    <tr><th>CPU</th><td>{html.escape(system_info.get('cpu', 'N/A'))}</td></tr>
                    <tr><th>Memory</th><td>{html.escape(system_info.get('memory', 'N/A'))}</td></tr>
                    <tr><th>Uptime</th><td>{html.escape(system_info.get('uptime', 'N/A'))}</td></tr>
                    <tr><th>Last Boot</th><td>{html.escape(system_info.get('last_boot', 'N/A'))}</td></tr>
                </table>
            </div>
            
            {graph_html}

            <div class="section">
                <h2>ğŸŒ ë„¤íŠ¸ì›Œí¬ ì •ë³´</h2>
                <h3>IP4 ìƒì„¸ ì •ë³´</h3>
                <table class="data-table">
                    <thead><tr><th>Interface</th><th>Master IF</th><th>MAC Address</th><th>MTU</th><th>State</th><th>IPv4 Address</th></tr></thead>
                    <tbody>{ip4_details_rows}</tbody>
                </table>
                <h3>ë¼ìš°íŒ… í…Œì´ë¸”</h3>
                <table class="data-table">
                    <thead><tr><th>Destination</th><th>Gateway</th><th>Device</th><th>Source</th></tr></thead>
                    <tbody>{create_table_rows(system_info.get('routing_table', []), ['destination', 'gateway', 'device', 'source'])}</tbody>
                </table>
                <h3>ETHTOOL ìƒíƒœ</h3>
                <table class="data-table">
                    <thead><tr><th>Interface</th><th>Link</th><th>Speed</th><th>Driver</th><th>Firmware</th></tr></thead>
                    <tbody>{ethtool_rows}</tbody>
                </table>
                <h3>NETDEV í†µê³„ (Receive)</h3>
                <table class="data-table">
                    <thead><tr><th>Interface</th><th>RxBytes</th><th>RxPackets</th><th>RxErrs</th><th>RxDrop</th><th>RxMulticast</th></tr></thead>
                    <tbody>{netdev_rx_rows}</tbody>
                </table>
                <h3>NETDEV í†µê³„ (Transmit)</h3>
                <table class="data-table">
                    <thead><tr><th>Interface</th><th>TxBytes</th><th>TxPackets</th><th>TxErrs</th><th>TxDrop</th><th>TxColls</th><th>TxCarrier</th></tr></thead>
                    <tbody>{netdev_tx_rows}</tbody>
                </table>
                <h3>ì†Œì¼“ í†µê³„</h3>
                <pre style="background:#eee; padding:10px; border-radius:4px;">{html.escape(chr(10).join(network_details.get('sockstat', [])))}</pre>
                <h3>ë„¤íŠ¸ì›Œí¬ ë³¸ë”©</h3>
                <table class="data-table">
                    <thead><tr><th>Device</th><th>Mode</th><th>Slaves</th></tr></thead>
                    <tbody>{create_table_rows(network_details.get('bonding', []), ['device', 'mode', 'slaves'])}</tbody>
                </table>
            </div>
            <div class="section">
                <h2>ï¿½ ìŠ¤í† ë¦¬ì§€ ë° íŒŒì¼ ì‹œìŠ¤í…œ</h2>
                <table class="data-table">
                    <thead><tr><th>Filesystem</th><th>Size</th><th>Used</th><th>Avail</th><th>Use%</th><th>Mounted on</th></tr></thead>
                    <tbody>{create_table_rows(storage_info, ['filesystem', 'size', 'used', 'avail', 'use%', 'mounted_on'])}</tbody>
                </table>
            </div>
            <div class="section">
                <h2>âš™ï¸ ë¦¬ì†ŒìŠ¤ ì‚¬ìš© í˜„í™©</h2>
                <h3>í”„ë¡œì„¸ìŠ¤ ìš”ì•½</h3>
                <table class="info-table">
                    <tr><th>Total Processes</th><td>{process_stats.get('total', 'N/A')}</td></tr>
                </table>
                <h3>Top Users of CPU & MEM</h3>
                <table class="data-table">
                    <thead><tr><th>USER</th><th>%CPU</th><th>%MEM</th><th>RSS</th></tr></thead>
                    <tbody>{create_table_rows(process_stats.get('by_user', []), ['user', 'cpu%', 'mem%', 'rss'])}</tbody>
                </table>
                <h3>Uninterruptible Sleep Processes ({len(process_stats.get('uninterruptible', []))})</h3>
                <table class="data-table">
                    <thead><tr><th>USER</th><th>PID</th><th>%CPU</th><th>%MEM</th><th>RSS</th><th>STAT</th><th>START</th><th>TIME</th><th>COMMAND</th></tr></thead>
                    <tbody>{create_table_rows(process_stats.get('uninterruptible', []), ['user', 'pid', 'cpu%', 'mem%', 'rss', 'stat', 'start', 'time', 'command'])}</tbody>
                </table>
                <h3>Zombie Processes ({len(process_stats.get('zombie', []))})</h3>
                <table class="data-table">
                    <thead><tr><th>USER</th><th>PID</th><th>%CPU</th><th>%MEM</th><th>RSS</th><th>STAT</th><th>START</th><th>TIME</th><th>COMMAND</th></tr></thead>
                    <tbody>{create_table_rows(process_stats.get('zombie', []), ['user', 'pid', 'cpu%', 'mem%', 'rss', 'stat', 'start', 'time', 'command'])}</tbody>
                </table>
                <h3>Top 5 Processes (CPU)</h3>
                <table class="data-table">
                    <thead><tr><th>PID</th><th>User</th><th>CPU %</th><th>Command</th></tr></thead>
                    <tbody>{create_table_rows(process_stats.get('top_cpu', []), ['pid', 'user', 'cpu%', 'command'])}</tbody>
                </table>
                <h3>Top 5 Processes (Memory)</h3>
                <table class="data-table">
                    <thead><tr><th>PID</th><th>User</th><th>RSS (KiB)</th><th>Command</th></tr></thead>
                    <tbody>{create_table_rows(process_stats.get('top_mem', []), ['pid', 'user', 'rss', 'command'])}</tbody>
                </table>
            </div>
            <div class="section">
                <h2>ğŸ”§ ì‹¤íŒ¨í•œ ì„œë¹„ìŠ¤</h2>
                <ul class="issue-list critical-list">{''.join(f"<li>{html.escape(service)}</li>" for service in failed_services) or "<li>ì‹¤íŒ¨í•œ ì„œë¹„ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.</li>"}</ul>
            </div>

            <!-- AI ë¶„ì„ ì„¹ì…˜ -->
            <div class="section">
                <h2>ğŸš¨ AI ë¶„ì„: ì‹¬ê°í•œ ì´ìŠˆ ({len(critical_issues)}ê°œ)</h2>
                <ul class="issue-list critical-list">{''.join(f"<li>{html.escape(issue)}</li>" for issue in critical_issues) or "<li>ë°œê²¬ëœ ì‹¬ê°í•œ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.</li>"}</ul>
            </div>
            <div class="section">
                <h2>âš ï¸ AI ë¶„ì„: ê²½ê³  ì‚¬í•­ ({len(warnings)}ê°œ)</h2>
                <ul class="issue-list">{''.join(f"<li>{html.escape(warning)}</li>" for warning in warnings) or "<li>íŠ¹ë³„í•œ ê²½ê³  ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.</li>"}</ul>
            </div>
            <div class="section">
                <h2>ğŸ’¡ AI ë¶„ì„: ê¶Œì¥ì‚¬í•­ ({len(recommendations)}ê°œ)</h2>
                <table class="data-table">
                    <thead><tr><th>ìš°ì„ ìˆœìœ„</th><th>ì¹´í…Œê³ ë¦¬</th><th>ë¬¸ì œì </th><th>í•´ê²° ë°©ì•ˆ</th></tr></thead>
                    <tbody>{create_table_rows(recommendations, ['priority', 'category', 'issue', 'solution'])}</tbody>
                </table>
            </div>
            <div class="section">
                <h2>ğŸ¤– AI ì¢…í•© ë¶„ì„</h2>
                <div class="ai-summary-card">
                    <p><b>ì¢…í•© ìƒíƒœ:</b> <span class="ai-status">{status}</span> (ê±´ê°•ë„ ì ìˆ˜: {score}/100)</p>
                    <p><b>ìš”ì•½:</b> {summary}</p>
                </div>
            </div>

            <!-- ë³´ì•ˆ ë‰´ìŠ¤ ì„¹ì…˜ -->
            <div class="section">
                <h2>ğŸ›¡ï¸ ë³´ì•ˆ ë‰´ìŠ¤ (ê°€ì¥ ì¤‘ìš”í•œ 10ê°œ)</h2>
                <table class="data-table">
                    <thead><tr><th>CVE ì‹ë³„ì</th><th>ì‹¬ê°ë„</th><th>ìƒì„±ì¼</th><th>ìš”ì•½</th></tr></thead>
                    <tbody>{create_table_rows(security_news, ['CVE', 'severity', 'public_date', 'bugzilla_description'])}</tbody>
                </table>
                <p style="font-size: 12px; text-align: center;">ë³´ì•ˆ ì •ë³´ì— ëŒ€í•œ ìƒì„¸ ë‚´ìš©ì€ <a href="https://access.redhat.com/security/security-updates/security-advisories" target="_blank">Red Hat Security Advisories</a> ì‚¬ì´íŠ¸ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
            </div>
        </div>
        <footer>ë³´ê³ ì„œ ìƒì„± ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</footer>
    </div>
</body>
</html>"""
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(html_template)
            print(f"âœ… HTML ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_file}")
            return str(report_file)
        except Exception as e:
            print(f"âŒ HTML ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            raise

def win_safe_filter(member, path):
    """Windows ê²½ë¡œì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ ë¬¸ìë¥¼ '_'ë¡œ ë°”ê¾¸ëŠ” í•„í„° í•¨ìˆ˜"""
    member.name = member.name.replace(':', '_')
    return member

def decompress_sosreport(archive_path: str, extract_dir: str) -> str:
    """sosreport ì••ì¶• íŒŒì¼ì„ ì§€ì •ëœ ë””ë ‰í† ë¦¬ì— í•´ì œí•©ë‹ˆë‹¤."""
    print(f"ì••ì¶• íŒŒì¼ í•´ì œ ì¤‘: {archive_path}")
    try:
        with tarfile.open(archive_path, 'r:*') as tar:
            if sys.platform == "win32":
                tar.extractall(path=extract_dir, filter=win_safe_filter)
            else:
                tar.extractall(path=extract_dir)
        print(f"âœ… ì••ì¶• í•´ì œ ì™„ë£Œ: {extract_dir}")
        return extract_dir
    except tarfile.TarError as e:
        raise Exception(f"ì••ì¶• íŒŒì¼ í•´ì œ ì‹¤íŒ¨: {e}")

def rmtree_onerror(func, path, exc_info):
    """shutil.rmtreeë¥¼ ìœ„í•œ ì˜¤ë¥˜ í•¸ë“¤ëŸ¬."""
    if isinstance(exc_info[1], PermissionError):
        try:
            os.chmod(path, 0o777)
            func(path)
        except Exception as e:
            print(f"onerror í•¸ë“¤ëŸ¬ì—ì„œë„ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {path}, ì˜¤ë¥˜: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='sosreport ì••ì¶• íŒŒì¼ AI ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„± ë„êµ¬', formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('sosreport_archive', nargs='?', help='ë¶„ì„í•  sosreport ì••ì¶• íŒŒì¼ ê²½ë¡œ (.tar.xz, .tar.gz ë“±)')
    parser.add_argument('--llm-url', required=True, help='LLM ì„œë²„ì˜ ê¸°ë³¸ URL')
    parser.add_argument('--endpoint-path', default='/v1/chat/completions', help='APIì˜ Chat Completions ì—”ë“œí¬ì¸íŠ¸ ê²½ë¡œ')
    parser.add_argument('--model', help='ì‚¬ìš©í•  LLM ëª¨ë¸ ì´ë¦„ (list-models ì‚¬ìš© ì‹œ ë¶ˆí•„ìš”)')
    parser.add_argument('--api-token', help='API ì¸ì¦ í† í°. LLM_API_TOKEN í™˜ê²½ ë³€ìˆ˜ë¡œë„ ì„¤ì • ê°€ëŠ¥')
    parser.add_argument('--output', '-o', default='output', help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: output)')
    parser.add_argument('--no-html', action='store_true', help='HTML ë³´ê³ ì„œ ìƒì„±ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.')
    parser.add_argument('--list-models', action='store_true', help='ì„œë²„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.')
    parser.add_argument('--test-only', action='store_true', help='LLM ì—°ê²° í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰ (ëª¨ë¸ ì´ë¦„ í•„ìš”)')
    
    args = parser.parse_args()
    api_token = args.api_token or os.getenv('LLM_API_TOKEN')
    
    if not plt:
        print("ê²½ê³ : 'matplotlib' ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê·¸ë˜í”„ ìƒì„± ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.", file=sys.stderr)
        print("'pip install matplotlib' ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.", file=sys.stderr)

    analyzer = AIAnalyzer(
        llm_url=args.llm_url, model_name=args.model,
        endpoint_path=args.endpoint_path, api_token=api_token,
        output_dir=args.output
    )

    if args.list_models:
        analyzer.list_available_models()
        sys.exit(0)

    if args.test_only:
        if not args.model: parser.error("--test-only ì˜µì…˜ì€ --model ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        if analyzer.check_llm_service() and analyzer.test_llm_connection():
            print("\nâœ… LLM ì„œë¹„ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        else:
            print("\nâŒ LLM ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
        sys.exit(0)

    if not args.sosreport_archive:
        parser.error("ë¶„ì„í•  sosreport ì••ì¶• íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
    if not args.model:
        parser.error("ë¶„ì„ì„ ìœ„í•´ì„œëŠ” --model ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    if not os.path.exists(args.sosreport_archive):
        print(f"âŒ ì…ë ¥ëœ ì••ì¶• íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.sosreport_archive}")
        sys.exit(1)

    os.makedirs(args.output, exist_ok=True)
    
    temp_extract_dir = Path(args.output) / f"temp_{Path(args.sosreport_archive).stem}_{int(time.time())}"
    
    try:
        decompress_sosreport(args.sosreport_archive, str(temp_extract_dir))
        
        parser = SosreportParser(str(temp_extract_dir))
        sos_data = parser.parse()

        base_name = Path(args.sosreport_archive).stem.replace('.tar', '')
        parsed_data_path = Path(args.output) / f"{base_name}_extracted_data.json"
        try:
            with open(parsed_data_path, 'w', encoding='utf-8') as f:
                json.dump(sos_data, f, indent=2, ensure_ascii=False)
            print(f"âœ… ì¶”ì¶œëœ ë°ì´í„° JSON íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ: {parsed_data_path}")
        except Exception as e:
            print(f"âŒ ì¶”ì¶œëœ ë°ì´í„° JSON ì €ì¥ ì‹¤íŒ¨: {e}")

        prompt = analyzer.create_analysis_prompt(sos_data)
        result = analyzer.perform_ai_analysis(prompt)
        print("âœ… AI ì‹œìŠ¤í…œ ë¶„ì„ ì™„ë£Œ!")

        sos_data['security_news'] = analyzer.fetch_security_news(sos_data)
        
        graphs = analyzer.create_performance_graphs(sos_data.get("performance_data", {}))
        
        results = {}
        if not args.no_html:
            html_path = analyzer.create_html_report(result, sos_data, graphs, args.output, args.sosreport_archive)
            results['html_file'] = html_path
        
        results['extracted_data_file'] = str(parsed_data_path)

        print("\në¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        if 'html_file' in results:
            print(f"  - HTML ë³´ê³ ì„œ: {results['html_file']}")
        if 'extracted_data_file' in results:
            print(f"  - ì›ë³¸ ì¶”ì¶œ ë°ì´í„° (JSON): {results['extracted_data_file']}")

    except Exception as e:
        print(f"\nâŒ ì „ì²´ ë¶„ì„ ê³¼ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)
    finally:
        if os.path.exists(temp_extract_dir):
            print(f"ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬: {temp_extract_dir}")
            try:
                shutil.rmtree(temp_extract_dir, onerror=rmtree_onerror)
                print("âœ… ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ ì™„ë£Œ.")
            except Exception as e:
                print(f"âŒ ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ì— ìµœì¢… ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}. ìˆ˜ë™ìœ¼ë¡œ ì‚­ì œí•´ì£¼ì„¸ìš”: {temp_extract_dir}")

if __name__ == "__main__":
    main()
