#!/usr/bin/env python3
"""
sosreport ì••ì¶• íŒŒì¼ AI ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„± ëª¨ë“ˆ
sosreport ì••ì¶• íŒŒì¼ì„ ì…ë ¥ë°›ì•„ ì••ì¶• í•´ì œ, ë°ì´í„° ì¶”ì¶œ, AI ë¶„ì„, HTML ë³´ê³ ì„œ ìƒì„±ì„ í•œ ë²ˆì— ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    # ê¸°ë³¸ ì‚¬ìš©ë²• (sosreport ì••ì¶• íŒŒì¼ì„ ì…ë ¥)
    python3 ai_analyzer.py sosreport-archive.tar.xz --llm-url <URL> --model <MODEL> --api-token <TOKEN>
"""

import os
import sys
import json
import requests
import argparse
import time
import re
import tarfile
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, Optional, List
import html # HTML ì´ìŠ¤ì¼€ì´í”„ë¥¼ ìœ„í•´ ì¶”ê°€
import io
import base64
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- ê·¸ë˜í”„ ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---
# "pip install matplotlib" ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜ í•„ìš”
try:
    import matplotlib
    matplotlib.use('Agg') # GUI ë°±ì—”ë“œ ì—†ì´ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì„¤ì •
    import matplotlib.pyplot as plt
    import matplotlib.font_manager as fm
except ImportError:
    matplotlib = None
    plt = None

# --- ì›¹ ìŠ¤í¬ë ˆì´í•‘ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---
# "pip install beautifulsoup4" ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜ í•„ìš”
try:
    from bs4 import BeautifulSoup
except ImportError:
    BeautifulSoup = None

class SosreportParser:
    """sosreport ì••ì¶• í•´ì œ í›„ ë””ë ‰í† ë¦¬ì—ì„œ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ JSON êµ¬ì¡°ë¡œ ë§Œë“­ë‹ˆë‹¤."""
    def __init__(self, extract_path: str):
        self.extract_path = Path(extract_path)
        subdirs = [d for d in self.extract_path.iterdir() if d.is_dir()]
        self.base_path = subdirs[0] if len(subdirs) == 1 else self.extract_path
        print(f"sosreport ë°ì´í„° ë¶„ì„ ê²½ë¡œ: {self.base_path}")
        self.today_date_str = datetime.now().strftime('%Y%m%d')
        self.today_sar_file_pattern = re.compile(f"sar{datetime.now().strftime('%d')}")


    def _read_file(self, possible_paths: List[str], default: str = 'N/A') -> str:
        """
        ì—¬ëŸ¬ ì˜ˆìƒ ê²½ë¡œ ì¤‘ íŒŒì¼ì„ ì°¾ì•„ ì•ˆì „í•˜ê²Œ ì½ì–´ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        for file_path in possible_paths:
            full_path = self.base_path / file_path
            if full_path.exists():
                try:
                    return full_path.read_text(encoding='utf-8', errors='ignore').strip()
                except Exception as e:
                    print(f"ê²½ê³ : '{file_path}' íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
                    return "íŒŒì¼ ì½ê¸° ì˜¤ë¥˜"
        return default
    
    def _parse_installed_packages(self) -> List[str]:
        """installed-rpms íŒŒì¼ì—ì„œ 'íŒ¨í‚¤ì§€-ë²„ì „-ë¦´ë¦¬ì¦ˆ' ì „ì²´ ë¬¸ìì—´ì„ íŒŒì‹±í•©ë‹ˆë‹¤."""
        rpm_content = self._read_file([
            'installed-rpms', 
            'sos_commands/rpm/sh_-c_rpm_--nodigest_-qa_--qf_NAME_-_VERSION_-_RELEASE_._ARCH_INSTALLTIME_date_awk_-F_printf_-59s_s_n_1_2_sort_-V', 
            'sos_commands/rpm/sh_-c_rpm_--nodigest_-qa_--qf_-59_NVRA_INSTALLTIME_date_sort_-V'
        ])

        if rpm_content == 'N/A' or not rpm_content.strip():
            print("âš ï¸ 'installed-rpms' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            return []
        
        packages = []
        package_pattern = re.compile(r'^([a-zA-Z0-9_.+-]+-\d+.*)')
        for line in rpm_content.split('\n'):
            line = line.strip()
            if not line or line.startswith(('gpg-pubkey', 'warning:', 'error:')):
                continue
            
            match = package_pattern.match(line)
            if match:
                packages.append(match.group(1))
            else:
                parts = line.split()
                if len(parts) > 0:
                    packages.append(parts[0])

        unique_packages = sorted(list(set(packages)))
        print(f"âœ… ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€(ë²„ì „ í¬í•¨) íŒŒì‹± ì™„ë£Œ: {len(unique_packages)}ê°œ")
        return unique_packages

    def _parse_system_details(self) -> Dict[str, Any]:
        """xsos ìŠ¤íƒ€ì¼ì˜ ìƒì„¸ ì‹œìŠ¤í…œ ì •ë³´ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        details = {}
        details['hostname'] = self._read_file(['hostname', 'sos_commands/general/hostname', 'proc/sys/kernel/hostname'])
        details['os_version'] = self._read_file(['etc/redhat-release'])
        
        # Kernel ë²„ì „ë§Œ ì •í™•íˆ ì¶”ì¶œ
        uname_content = self._read_file(['uname', 'sos_commands/kernel/uname_-a'])
        uname_line = uname_content.split('\n')[0]
        parts = uname_line.split()
        if len(parts) >= 3:
            details['kernel'] = parts[2]
        else:
            details['kernel'] = uname_line # Fallback

        dmidecode_content = self._read_file(['dmidecode', 'sos_commands/hardware/dmidecode'])
        model_match = re.search(r'Product Name:\s*(.*)', dmidecode_content)
        details['system_model'] = model_match.group(1).strip() if model_match else 'N/A'
        lscpu_content = self._read_file(['lscpu', 'sos_commands/processor/lscpu'])
        cpu_model = re.search(r'Model name:\s+(.*)', lscpu_content)
        cpu_cores = re.search(r'^CPU\(s\):\s+(\d+)', lscpu_content, re.MULTILINE)
        details['cpu'] = f"{cpu_cores.group(1) if cpu_cores else 'N/A'} x {cpu_model.group(1).strip() if cpu_model else 'N/A'}"
        meminfo_content = self._read_file(['proc/meminfo'])
        mem_total = re.search(r'MemTotal:\s+(\d+)\s+kB', meminfo_content)
        details['memory'] = f"{int(mem_total.group(1)) / 1024 / 1024:.1f} GiB" if mem_total else 'N/A'
        
        # Uptime ì •ë³´ë§Œ ì •í™•íˆ ì¶”ì¶œ
        uptime_content = self._read_file(['uptime', 'sos_commands/general/uptime', 'sos_commands/host/uptime'])
        uptime_match = re.search(r'up\s+(.*?),\s+\d+\s+user', uptime_content)
        if uptime_match:
            details['uptime'] = uptime_match.group(1).strip()
        else:
            uptime_match_simple = re.search(r'up\s+(.*)', uptime_content)
            if uptime_match_simple:
                 details['uptime'] = uptime_match_simple.group(1).split(',')[0].strip()
            else:
                 details['uptime'] = uptime_content # Final fallback

        last_boot_str = "N/A"
        proc_stat_content = self._read_file(['proc/stat'])
        btime_match = re.search(r'^btime\s+(\d+)', proc_stat_content, re.MULTILINE)
        if btime_match:
            try:
                epoch_time = int(btime_match.group(1))
                boot_datetime = datetime.fromtimestamp(epoch_time)
                timedatectl_content = self._read_file(['sos_commands/host/timedatectl_status'])
                tz_match = re.search(r'Time zone:\s+[\w/]+\s+\((.*?),', timedatectl_content)
                tz_abbr = tz_match.group(1) if tz_match else ""
                formatted_date = boot_datetime.strftime(f'%a %b %d %H:%M:%S {tz_abbr} %Y').strip()
                last_boot_str = f"{formatted_date} (epoch: {epoch_time})"
            except (ValueError, OSError) as e:
                print(f"ê²½ê³ : ë¶€íŒ… ì‹œê°„(epoch) ë³€í™˜ ì‹¤íŒ¨: {e}")
                last_boot_str = "Epoch ë³€í™˜ ì˜¤ë¥˜"
        if last_boot_str == "N/A" or "ì˜¤ë¥˜" in last_boot_str:
             last_boot_str = self._read_file(['sos_commands/boot/who_-b', 'sos_commands/startup/who_-b']).replace('system boot', '').strip()
        details['last_boot'] = last_boot_str
        
        return details

    def _parse_storage(self) -> List[Dict[str, str]]:
        """df -h ì¶œë ¥ì—ì„œ íŒŒì¼ ì‹œìŠ¤í…œ ì‚¬ìš©ëŸ‰ì„ íŒŒì‹±í•©ë‹ˆë‹¤."""
        df_content = self._read_file(['df', 'sos_commands/filesys/df_-alPh'])
        filesystems = []
        for line in df_content.split('\n')[1:]:
            parts = line.split()
            if len(parts) >= 6 and parts[0].startswith('/'):
                filesystems.append({'filesystem': parts[0], 'size': parts[1], 'used': parts[2], 'avail': parts[3], 'use%': parts[4], 'mounted_on': parts[5]})
        return filesystems

    def _parse_process_stats(self) -> Dict[str, Any]:
        """ps ëª…ë ¹ì–´ ì¶œë ¥ì—ì„œ í”„ë¡œì„¸ìŠ¤ ê´€ë ¨ í†µê³„ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        ps_content = self._read_file(['sos_commands/process/ps_auxwww', 'sos_commands/process/ps_auxwwwm', 'ps'])
        if ps_content == 'N/A':
            return {'total': 0, 'by_user': [], 'uninterruptible': [], 'zombie': [], 'top_cpu': [], 'top_mem': []}

        lines = ps_content.split('\n')
        header_found = False
        processes = []
        
        for line in lines:
            if re.match(r'USER\s+PID\s+%CPU', line):
                header_found = True
                continue
            if not header_found:
                continue

            parts = line.split(maxsplit=10)
            if len(parts) >= 11:
                try:
                    processes.append({
                        'user': parts[0], 'pid': parts[1], 'cpu%': float(parts[2]),
                        'mem%': float(parts[3]), 'vsz': int(parts[4]), 'rss': int(parts[5]),
                        'stat': parts[7], 'start': parts[8], 'time': parts[9], 'command': parts[10]
                    })
                except (ValueError, IndexError):
                    continue
        
        total_processes = len(processes)
        uninterruptible = [p for p in processes if 'D' in p['stat']]
        zombie = [p for p in processes if 'Z' in p['stat']]
        
        user_stats = {}
        for p in processes:
            user = p['user']
            if user not in user_stats:
                user_stats[user] = {'cpu%': 0.0, 'mem%': 0.0, 'rss': 0}
            user_stats[user]['cpu%'] += p['cpu%']
            user_stats[user]['mem%'] += p['mem%']
            user_stats[user]['rss'] += p['rss']
        
        top_users = sorted(user_stats.items(), key=lambda item: item[1]['cpu%'], reverse=True)[:5]
        
        formatted_top_users = []
        for user, stats in top_users:
            formatted_top_users.append({
                'user': user,
                'cpu%': f"{stats['cpu%']:.1f}%",
                'mem%': f"{stats['mem%']:.1f}%",
                'rss': f"{stats['rss'] / 1024 / 1024:.2f} GiB" if stats['rss'] > 1024*1024 else f"{stats['rss'] / 1024:.2f} MiB"
            })
        
        top_cpu = sorted(processes, key=lambda p: p['cpu%'], reverse=True)[:5]
        top_mem = sorted(processes, key=lambda p: p['rss'], reverse=True)[:5]

        print(f"âœ… í”„ë¡œì„¸ìŠ¤ í†µê³„ íŒŒì‹± ì™„ë£Œ: {total_processes}ê°œ í”„ë¡œì„¸ìŠ¤")
        return {
            'total': total_processes,
            'by_user': formatted_top_users,
            'uninterruptible': uninterruptible,
            'zombie': zombie,
            'top_cpu': top_cpu,
            'top_mem': top_mem
        }

    def _parse_failed_services(self) -> List[str]:
        """systemctl list-units ì¶œë ¥ì—ì„œ ì‹¤íŒ¨í•œ ì„œë¹„ìŠ¤ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        systemctl_content = self._read_file(['sos_commands/systemd/systemctl_list-units_--all'])
        failed_services = []
        for line in systemctl_content.split('\n'):
            if 'failed' in line:
                parts = line.strip().split()
                if len(parts) >= 4:
                    failed_services.append(f"{parts[0]} - {' '.join(parts[1:4])}")
        return failed_services

    def _parse_ip4_details(self) -> List[Dict[str, str]]:
        """ip addr ëª…ë ¹ì–´ ì¶œë ¥ì—ì„œ ìƒì„¸ ì¸í„°í˜ì´ìŠ¤ ì •ë³´ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        ip_addr_content = self._read_file(['sos_commands/networking/ip_addr', 'sos_commands/networking/ip_-d_address'])
        if ip_addr_content == 'N/A': return []
        
        interfaces = []
        blocks = re.split(r'^\d+:\s+', ip_addr_content, flags=re.MULTILINE)
        if not blocks[0].strip():
            blocks.pop(0)

        for block in blocks:
            if not block.strip(): continue
            iface_data = {}
            
            name_match = re.match(r'([\w.-]+):', block)
            if not name_match: continue
            iface_data['iface'] = name_match.group(1)

            mtu_match = re.search(r'mtu\s+(\d+)', block)
            iface_data['mtu'] = mtu_match.group(1) if mtu_match else '-'
            
            state_match = re.search(r'state\s+(\w+)', block)
            iface_data['state'] = state_match.group(1).lower() if state_match else 'unknown'
            
            master_match = re.search(r'master\s+([\w.-]+)', block)
            iface_data['master'] = master_match.group(1) if master_match else '-'

            mac_match = re.search(r'link/\w+\s+([\da-fA-F:]+)', block)
            iface_data['mac'] = mac_match.group(1) if mac_match else '-'

            ip_match = re.search(r'inet\s+([\d.]+/\d+)', block)
            iface_data['ipv4'] = ip_match.group(1) if ip_match else '-'
            
            interfaces.append(iface_data)
            
        return interfaces

    def _parse_network_details(self) -> Dict[str, Any]:
        """NETDEV, SOCKSTAT, BONDING, ETHTOOL ì •ë³´ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        details = {'netdev': [], 'sockstat': [], 'bonding': [], 'ethtool': {}}

        netdev_content = self._read_file(['proc/net/dev'])
        for line in netdev_content.split('\n')[2:]:
            if ':' not in line: continue
            iface, stats = line.split(':', 1)
            iface = iface.strip()
            stat_values = stats.split()
            if len(stat_values) == 16:
                details['netdev'].append({
                    'iface': iface,
                    'rx_bytes': int(stat_values[0]), 'rx_packets': int(stat_values[1]), 'rx_errs': int(stat_values[2]), 'rx_drop': int(stat_values[3]),
                    'rx_fifo': int(stat_values[4]), 'rx_frame': int(stat_values[5]), 'rx_compressed': int(stat_values[6]), 'rx_multicast': int(stat_values[7]),
                    'tx_bytes': int(stat_values[8]), 'tx_packets': int(stat_values[9]), 'tx_errs': int(stat_values[10]), 'tx_drop': int(stat_values[11]),
                    'tx_fifo': int(stat_values[12]), 'tx_colls': int(stat_values[13]), 'tx_carrier': int(stat_values[14]), 'tx_compressed': int(stat_values[15])
                })

        details['sockstat'] = self._read_file(['proc/net/sockstat']).split('\n')

        bonding_dir = self.base_path / 'proc/net/bonding'
        if bonding_dir.is_dir():
            for bond_file in bonding_dir.iterdir():
                bond_content = bond_file.read_text(encoding='utf-8', errors='ignore')
                bond_info = {'device': bond_file.name}
                mode_match = re.search(r'Bonding Mode:\s*(.*)', bond_content)
                if mode_match: bond_info['mode'] = mode_match.group(1).strip()
                slaves = re.findall(r'Slave Interface:\s*(\w+)', bond_content)
                bond_info['slaves'] = slaves
                details['bonding'].append(bond_info)
        
        ethtool_dir = self.base_path / 'sos_commands/networking'
        if ethtool_dir.is_dir():
            all_ifaces = [dev['iface'] for dev in details['netdev']]
            for iface_name in all_ifaces:
                details['ethtool'][iface_name] = {}
                
                content = self._read_file([f'sos_commands/networking/ethtool_{iface_name}'])
                link_match = re.search(r'Link detected:\s*(yes|no)', content)
                speed_match = re.search(r'Speed:\s*(.*)', content)
                driver_match = re.search(r'driver:\s*(.*)', content)
                fw_match = re.search(r'firmware-version:\s*(.*)', content)
                
                details['ethtool'][iface_name]['link'] = link_match.group(1) if link_match else 'N/A'
                details['ethtool'][iface_name]['speed'] = speed_match.group(1).strip() if speed_match else 'N/A'
                details['ethtool'][iface_name]['driver'] = driver_match.group(1).strip() if driver_match else 'N/A'
                details['ethtool'][iface_name]['firmware'] = fw_match.group(1).strip() if fw_match else 'N/A'

                content_s = self._read_file([f'sos_commands/networking/ethtool_-S_{iface_name}'])
                errors = {}
                for line in content_s.split('\n'):
                    match = re.search(r'\s*(\w+.*):\s*(\d+)', line)
                    if match and int(match.group(2)) > 0:
                        errors[match.group(1).strip()] = match.group(2)
                if errors:
                    details['ethtool'][iface_name]['errors'] = errors
        
        return details

    def _parse_routing_table(self) -> List[Dict[str, str]]:
        """ë¼ìš°íŒ… í…Œì´ë¸” ì •ë³´ë¥¼ íŒŒì‹±í•˜ê³  ë¶ˆí•„ìš”í•œ í•­ëª©ì„ í•„í„°ë§í•©ë‹ˆë‹¤."""
        routing_content = self._read_file(['sos_commands/networking/ip_route_show_table_all', 'sos_commands/networking/ip_route_show'])
        routes = []
        exclusion_keywords = ["broadcast", "local", "unreachable"]

        for line in routing_content.split('\n'):
            if not line.strip(): continue
            parts = line.split()
            
            if parts[0] in exclusion_keywords:
                continue

            route_info = {'destination': parts[0], 'gateway': '-', 'device': '-', 'source': '-'}
            
            try:
                if 'via' in parts:
                    route_info['gateway'] = parts[parts.index('via') + 1]
                if 'dev' in parts:
                    route_info['device'] = parts[parts.index('dev') + 1]
                if 'src' in parts:
                    route_info['source'] = parts[parts.index('src') + 1]
            except IndexError:
                continue

            if route_info['source'].startswith('127.'): continue
            if route_info['destination'].lower() != 'default' and route_info['source'] == '-': continue
            
            routes.append(route_info)
        return routes

    def _parse_sar_data(self) -> Dict[str, List[Dict[str, Any]]]:
        """
        sosreport ë‚´ì˜ /var/log/sa/sar* íŒŒì¼ë“¤ì„ ì½ì–´ CPU, Memory, Network, Disk ë°ì´í„°ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
        sosreportê°€ ì‹¤í–‰ëœ ë‹¹ì¼ì˜ ë°ì´í„°ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """
        print("sar ì„±ëŠ¥ ë°ì´í„° íŒŒì‹± ì¤‘...")
        sa_dir = self.base_path / 'var/log/sa'
        today_sar_content = ""

        if sa_dir.is_dir():
            # sosreport ì‹¤í–‰ ë‹¹ì¼ì˜ sar íŒŒì¼ (ì˜ˆ: sarDD)
            today_sar_files = [f for f in sa_dir.iterdir() if self.today_sar_file_pattern.match(f.name)]
            # íŠ¹ì • ë‚ ì§œ í˜•ì‹ì˜ sar íŒŒì¼ (ì˜ˆ: sarYYYYMMDD)
            specific_date_sar_files = [f for f in sa_dir.iterdir() if f.name.startswith('sar') and self.today_date_str in f.name]
            
            target_files = today_sar_files + specific_date_sar_files
            
            if target_files:
                for file_path in sorted(list(set(target_files))): # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
                    print(f"  -> ë‹¹ì¼ sar ë°ì´í„° íŒŒì¼ ë°œê²¬: {file_path.name}")
                    try:
                        # sar ë°”ì´ë„ˆë¦¬ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ sadf ëª…ë ¹ì–´ ì‚¬ìš© ì‹œë„
                        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” sadfê°€ ì—†ìœ¼ë¯€ë¡œ, í…ìŠ¤íŠ¸ ê¸°ë°˜ sar ì¶œë ¥ íŒŒì¼ë§Œ ì²˜ë¦¬
                        today_sar_content += file_path.read_text(encoding='utf-8', errors='ignore') + "\n"
                    except Exception as e:
                        print(f"ê²½ê³ : '{file_path.name}' íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            else:
                print("  -> ë‹¹ì¼ì˜ sar íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. sos_commands/monitoring/sar_-A ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")

        if not today_sar_content.strip():
            # sar íŒŒì¼ì´ ì—†ê±°ë‚˜ ë°”ì´ë„ˆë¦¬ í˜•ì‹ì¼ ê²½ìš°, sosreportì˜ í…ìŠ¤íŠ¸ ë¤í”„ë¥¼ ì‚¬ìš©
            today_sar_content = self._read_file(['sos_commands/monitoring/sar_-A'])

        if not today_sar_content.strip():
            print("âš ï¸ ë¶„ì„í•  sar ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {}

        performance_data = {'cpu': [], 'memory': [], 'network': [], 'disk': []}

        # ì •ê·œ í‘œí˜„ì‹ ìˆ˜ì • (ë” ìœ ì—°í•˜ê²Œ)
        # CPU (all)
        cpu_section = re.search(r'(\d{2}:\d{2}:\d{2}\s+(?:AM|PM)\s+CPU\s+%user\s+%nice\s+%system\s+%iowait\s+%steal\s+%idle\n(?:.*\n)+?)(?=\n\n|\Z)', today_sar_content, re.MULTILINE)
        if cpu_section:
            for line in cpu_section.group(1).strip().split('\n'):
                parts = line.split()
                if len(parts) >= 9 and parts[2] == 'all':
                    performance_data['cpu'].append({'timestamp': parts[0] + " " + parts[1], 'user': float(parts[3]), 'system': float(parts[5]), 'iowait': float(parts[6]), 'idle': float(parts[8])})

        # Memory
        mem_section = re.search(r'(\d{2}:\d{2}:\d{2}\s+(?:AM|PM)\s+kbmemfree\s+kbmemused\s+%memused\s+kbbuffers\s+kbcached\s+kbcommit\s+%commit\n(?:.*\n)+?)(?=\n\n|\Z)', today_sar_content, re.MULTILINE)
        if mem_section:
            for line in mem_section.group(1).strip().split('\n'):
                parts = line.split()
                if len(parts) >= 5 and parts[0].count(':') == 2:
                    performance_data['memory'].append({'timestamp': parts[0] + " " + parts[1], 'memused_percent': float(parts[4])})

        # Network
        net_section = re.search(r'(\d{2}:\d{2}:\d{2}\s+(?:AM|PM)\s+IFACE\s+rxpck/s\s+txpck/s\s+rxkB/s\s+txkB/s\s+rxcmp/s\s+txcmp/s\s+rxmcst/s\n(?:.*\n)+?)(?=\n\n|\Z)', today_sar_content, re.MULTILINE)
        if net_section:
            net_agg = {}
            for line in net_section.group(1).strip().split('\n'):
                parts = line.split()
                if len(parts) >= 7 and parts[2] not in ('IFACE', 'lo'):
                    ts = parts[0] + " " + parts[1]
                    if ts not in net_agg: net_agg[ts] = {'rxkB': 0.0, 'txkB': 0.0}
                    net_agg[ts]['rxkB'] += float(parts[5])
                    net_agg[ts]['txkB'] += float(parts[6])
            for ts, data in net_agg.items():
                performance_data['network'].append({'timestamp': ts, **data})
        
        # Disk
        disk_section = re.search(r'(\d{2}:\d{2}:\d{2}\s+(?:AM|PM)\s+DEV\s+tps\s+rkB/s\s+wkB/s\s+areq-sz\s+aqu-sz\s+await\s+%util\n(?:.*\n)+?)(?=\n\n|\Z)', today_sar_content, re.MULTILINE)
        if disk_section:
            disk_agg = {}
            for line in disk_section.group(1).strip().split('\n'):
                parts = line.split()
                if len(parts) >= 9 and parts[2] != 'DEV':
                    ts = parts[0] + " " + parts[1]
                    if ts not in disk_agg: disk_agg[ts] = {'read_kB': 0.0, 'write_kB': 0.0, 'util_percent': 0.0}
                    # ì—¬ëŸ¬ ë””ìŠ¤í¬ì˜ í‰ê·  ë˜ëŠ” í•©ê³„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆìŒ. ì—¬ê¸°ì„œëŠ” í•©ê³„ë¡œ ì²˜ë¦¬.
                    disk_agg[ts]['read_kB'] += float(parts[4])
                    disk_agg[ts]['write_kB'] += float(parts[5])
                    disk_agg[ts]['util_percent'] += float(parts[9]) # %utilì´ ê°€ì¥ ë§ˆì§€ë§‰ ì»¬ëŸ¼
            for ts, data in disk_agg.items():
                performance_data['disk'].append({'timestamp': ts, **data})


        print("âœ… sar ì„±ëŠ¥ ë°ì´í„° íŒŒì‹± ì™„ë£Œ.")
        return performance_data

    def _parse_log_messages(self) -> List[str]:
        """
        var/log/messages* íŒŒì¼ì—ì„œ ì¤‘ë³µì„ ì œê±°í•˜ê³  í•µì‹¬ì ì¸ ì˜¤ë¥˜ ë° ê²½ê³  ë¡œê·¸ë¥¼ ì§€ëŠ¥ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """
        log_content = self._read_file(['var/log/messages', 'var/log/syslog'])
        if log_content == 'N/A' or not log_content.strip():
            print("âš ï¸ 'var/log/messages' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            return []

        # ë” êµ¬ì²´ì ì´ê³  ì‹¬ê°ë„ ë†’ì€ í‚¤ì›Œë“œ ì¶”ê°€
        keywords = [
            'error', 'failed', 'critical', 'panic', 'segfault', 
            'out of memory', 'i/o error', 'hardware error', 'nmi', 'call trace'
        ]
        warning_keyword = 'warning'

        unique_logs = {}

        # ë¡œê·¸ ë©”ì‹œì§€ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„, í˜¸ìŠ¤íŠ¸ëª…, í”„ë¡œì„¸ìŠ¤ëª…/PIDë¥¼ ì œê±°í•˜ëŠ” ì •ê·œì‹
        log_prefix_re = re.compile(
            r'^[A-Za-z]{3}\s+\d{1,2}\s+\d{2}:\d{2}:\d{2}\s+[\w.-]+\s+[^:]+:\s+'
        )
        
        lines = log_content.split('\n')
        print(f"ì´ {len(lines)}ì¤„ì˜ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ ë©”ì‹œì§€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤...")

        for line in lines:
            line_lower = line.lower()
            if not any(keyword in line_lower for keyword in keywords) and warning_keyword not in line_lower:
                continue

            core_message = log_prefix_re.sub('', line)
            if not core_message:
                core_message = line

            # ê°€ë³€ì ì¸ ë¶€ë¶„ì„ ì¼ë°˜í™”í•˜ì—¬ ê·¸ë£¹í™”
            normalized_message = re.sub(r'\b(sda|sdb|sdc|nvme0n1)\d*\b', 'sdX', core_message)
            normalized_message = re.sub(r'\b\d{4,}\b', 'N', normalized_message)
            normalized_message = re.sub(r'0x[0-9a-fA-F]+', '0xADDR', normalized_message)
            normalized_message = re.sub(r'\[\s*\d+\.\d+\]', '', normalized_message).strip()

            if not normalized_message:
                continue

            if normalized_message not in unique_logs:
                unique_logs[normalized_message] = {
                    'original_line': line,
                    'count': 0
                }
            unique_logs[normalized_message]['count'] += 1

        if not unique_logs:
            print("âœ… 'var/log/messages'ì—ì„œ ì‹¬ê°í•œ ì˜¤ë¥˜ë‚˜ ê²½ê³ ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []

        sorted_logs = sorted(unique_logs.items(), key=lambda item: item[1]['count'], reverse=True)

        formatted_results = []
        for normalized, data in sorted_logs[:100]:
            count = data['count']
            original_line = data['original_line']
            timestamp_match = re.match(r'^([A-Za-z]{3}\s+\d{1,2}\s+\d{2}:\d{2}:\d{2})', original_line)
            timestamp = timestamp_match.group(1) if timestamp_match else "Timestamp N/A"

            formatted_line = f"[{count}íšŒ] {timestamp} - {normalized}"
            formatted_results.append(formatted_line)
        
        print(f"âœ… 'var/log/messages'ì—ì„œ {len(formatted_results)}ê°œì˜ ê³ ìœ í•œ ë¬¸ì œì„± ë¡œê·¸ ê·¸ë£¹ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        return formatted_results

    def parse(self) -> Dict[str, Any]:
        """ì£¼ìš” sosreport íŒŒì¼ë“¤ì„ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        print("sosreport ë°ì´í„° íŒŒì‹± ì‹œì‘...")
        system_info = self._parse_system_details()
        system_info['routing_table'] = self._parse_routing_table()

        data = {
            "system_info": system_info,
            "ip4_details": self._parse_ip4_details(),
            "network_details": self._parse_network_details(),
            "storage": self._parse_storage(),
            "process_stats": self._parse_process_stats(),
            "failed_services": self._parse_failed_services(),
            "performance_data": self._parse_sar_data(),
            "installed_packages": self._parse_installed_packages(),
            "log_messages": self._parse_log_messages(),
            "analysis_timestamp": datetime.now().isoformat()
        }
        print("âœ… sosreport ë°ì´í„° íŒŒì‹± ì™„ë£Œ.")
        return data

class AIAnalyzer:
    def __init__(self, llm_url: str, model_name: Optional[str] = None, 
                 endpoint_path: str = "/v1/chat/completions",
                 api_token: Optional[str] = None,
                 timeout: int = 300,
                 output_dir: str = 'output'):
        """AI ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        match = re.search(r'https?://[^\s\)]+', llm_url)
        cleaned_url = match.group(0) if match else llm_url
        
        self.llm_url = cleaned_url.rstrip('/')
        self.model_name = model_name
        self.endpoint_path = endpoint_path
        self.completion_url = f"{self.llm_url}{self.endpoint_path}"
        self.api_token = api_token
        self.timeout = timeout
        self.session = requests.Session()
        self.output_dir = Path(output_dir)
        
        headers = {'Content-Type': 'application/json', 'Accept': 'application/json'}
        if self.api_token:
            headers['Authorization'] = f'Bearer {self.api_token}'
        self.session.headers.update(headers)
        
        self._setup_korean_font()


        print("AI ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"LLM ê¸°ë³¸ URL: {self.llm_url}")
        if self.model_name:
            print(f"ì‚¬ìš© ëª¨ë¸: {self.model_name}")

    def _setup_korean_font(self):
        """matplotlibì—ì„œ í•œê¸€ì„ ì§€ì›í•˜ê¸° ìœ„í•œ í°íŠ¸ ì„¤ì •"""
        if not plt:
            return
        
        # 1. ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ í°íŠ¸ì—ì„œ 'Nanum' ë˜ëŠ” 'Malgun' í°íŠ¸ ì°¾ê¸°
        font_paths = fm.findSystemFonts(fontpaths=None, fontext='ttf')
        korean_font_path = None
        for path in font_paths:
            if 'nanum' in path.lower() or 'malgun' in path.lower():
                korean_font_path = path
                break
        
        if korean_font_path:
            try:
                fm.fontManager.addfont(korean_font_path)
                font_name = fm.FontProperties(fname=korean_font_path).get_name()
                plt.rc('font', family=font_name)
                plt.rc('axes', unicode_minus=False) # ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ê¹¨ì§ ë°©ì§€
                print(f"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ: {font_name}")
            except Exception as e:
                print(f"âš ï¸ í•œê¸€ í°íŠ¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ê·¸ë˜í”„ ì œëª©ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            print("âš ï¸ ê²½ê³ : 'ë‚˜ëˆ”ê³ ë”•' ë˜ëŠ” 'ë§‘ì€ ê³ ë”•' í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê·¸ë˜í”„ì˜ í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


    def list_available_models(self):
        """ì„œë²„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•˜ê³  ì¶œë ¥í•©ë‹ˆë‹¤."""
        print(f"'{self.llm_url}' ì„œë²„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤...")
        models_url = f"{self.llm_url}/v1/models"
        try:
            response = self.session.get(models_url, timeout=20)
            if response.status_code != 200:
                print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: HTTP {response.status_code}, ë‚´ìš©: {response.text[:200]}")
                return

            models_data = response.json()
            if 'data' in models_data and models_data['data']:
                print("\n--- ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ---")
                for model in models_data['data']:
                    print(f"- {model.get('id')}")
                print("------------------------\n")
            else:
                print("âŒ ì‘ë‹µì—ì„œ ëª¨ë¸ ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except requests.exceptions.RequestException as e:
            print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def check_llm_service(self, max_retries: int = 3) -> bool:
        """LLM ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
        print("LLM ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì¤‘...")
        for attempt in range(max_retries):
            try:
                response = self.session.get(self.llm_url, timeout=10)
                if response.status_code in [200, 404, 401, 403]:
                    print(f"âœ… LLM ì„œë¹„ìŠ¤ ì—°ê²° ì„±ê³µ (ì‹œë„ {attempt + 1}/{max_retries})")
                    return True
            except requests.exceptions.RequestException as e:
                print(f"ì—°ê²° ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
            if attempt < max_retries - 1:
                time.sleep(5)
        print("âŒ 3ë²ˆ ì‹œë„ í›„ì—ë„ LLM ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return False

    def test_llm_connection(self) -> bool:
        """LLM ì—°ê²° í…ŒìŠ¤íŠ¸"""
        if not self.model_name:
            print("âš ï¸ ëª¨ë¸ ì´ë¦„ì´ ì§€ì •ë˜ì§€ ì•Šì•„ ì—°ê²° í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False
        print("LLM ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
        try:
            test_payload = {"model": self.model_name, "messages": [{"role": "user", "content": "Connection test. Reply with 'OK'."}], "max_tokens": 10}
            response = self.session.post(self.completion_url, json=test_payload, timeout=30)
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and result.get('choices'):
                    print(f"âœ… ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ: {result['choices'][0]['message']['content'].strip()}")
                    return True
            print(f"âŒ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: HTTP {response.status_code}, ë‚´ìš©: {response.text[:200]}")
            return False
        except Exception as e:
            print(f"âŒ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return False

    def perform_ai_analysis(self, prompt: str, is_news_request: bool = False) -> Any:
        """AI ë¶„ì„ ìˆ˜í–‰. ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ."""
        print("AI ë¶„ì„ ì‹œì‘...")
        try:
            payload = {
                "model": self.model_name,
                "messages": [
                    {"role": "system", "content": "You are a helpful assistant designed to output JSON."},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 16384, 
                "temperature": 0.1,
            }
            start_time = time.time()
            print(f"LLM API í˜¸ì¶œ ì¤‘... ({self.completion_url})")

            if is_news_request:
                llm_log_path = self.output_dir / "llm_security_news.log"
                with open(llm_log_path, 'a', encoding='utf-8') as f:
                    f.write("\n\n--- NEW PROMPT FOR SECURITY NEWS ---\n")
                    f.write(prompt)
                    f.write("\n\n--- LLM RESPONSE ---\n")
                print("\n--- LLMì—ê²Œ ë³´ë‚¸ ë³´ì•ˆ ë‰´ìŠ¤ í”„ë¡¬í”„íŠ¸ ---")
                print(prompt[:500] + "...")
                print("-------------------------------------\n")

            response = self.session.post(self.completion_url, json=payload, timeout=self.timeout)
            print(f"API ì‘ë‹µ ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ")

            if response.status_code != 200:
                raise ValueError(f"API í˜¸ì¶œ ì‹¤íŒ¨: HTTP {response.status_code}, ë‚´ìš©: {response.text[:500]}")
            
            result = response.json()
            if 'choices' not in result or not result['choices']:
                raise ValueError(f"API ì‘ë‹µì— 'choices' í‚¤ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì‘ë‹µ: {result}")

            ai_response = result['choices'][0]['message']['content']
            
            if is_news_request:
                with open(llm_log_path, 'a', encoding='utf-8') as f:
                    f.write(ai_response)

            return self._parse_ai_response(ai_response)
        except (requests.exceptions.RequestException, ValueError) as e:
            raise Exception(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def create_analysis_prompt(self, sosreport_data: Dict[str, Any]) -> str:
        """AI ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        print("AI ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        
        log_summary = sosreport_data.get("log_messages", [])
        
        data_to_send = {
            "system_info": sosreport_data.get("system_info"),
            "storage": sosreport_data.get("storage"),
            "failed_services": sosreport_data.get("failed_services"),
            "process_stats_summary": {
                "total": sosreport_data.get("process_stats", {}).get("total"),
                "zombie_count": len(sosreport_data.get("process_stats", {}).get("zombie", [])),
            },
            "recent_log_warnings_and_errors": log_summary
        }

        data_str = json.dumps(data_to_send, indent=2, ensure_ascii=False)

        prompt = f"""ë‹¹ì‹ ì€ Red Hat Enterprise Linux ì‹œìŠ¤í…œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ sosreport ë¶„ì„ ë°ì´í„°ì™€ ì‹œìŠ¤í…œ ë¡œê·¸ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê²€í† í•˜ê³  ì „ë¬¸ì ì¸ ì§„ë‹¨ì„ ì œê³µí•´ì£¼ì„¸ìš”.

## ë¶„ì„ ë°ì´í„°
```json
{data_str}
```

## ë¶„ì„ ê°€ì´ë“œë¼ì¸
- **ì‹¬ê°í•œ ì´ìŠˆ(critical_issues) íŒë‹¨ ê¸°ì¤€**: ë¡œê·¸ ë‚´ìš©ì— 'panic', 'segfault', 'out of memory', 'hardware error', 'i/o error', 'call trace'ì™€ ê°™ì€ ëª…ë°±í•œ ì‹œìŠ¤í…œ ì¥ì• ë‚˜ ë°ì´í„° ì†ìƒ ê°€ëŠ¥ì„±ì„ ì•”ì‹œí•˜ëŠ” í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°, **ë°˜ë“œì‹œ 'ì‹¬ê°í•œ ì´ìŠˆ'ë¡œ ë¶„ë¥˜**í•´ì•¼ í•©ë‹ˆë‹¤.
- **ê²½ê³ (warnings) íŒë‹¨ ê¸°ì¤€**: ë‹¹ì¥ ì‹œìŠ¤í…œ ì¥ì• ë¥¼ ì¼ìœ¼í‚¤ì§€ëŠ” ì•Šì§€ë§Œ, ì ì¬ì ì¸ ë¬¸ì œë¡œ ë°œì „í•  ìˆ˜ ìˆê±°ë‚˜ ì£¼ì˜ê°€ í•„ìš”í•œ ë¡œê·¸(ì˜ˆ: 'warning', 'failed' ë“±)ëŠ” 'ê²½ê³ 'ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.

## ë¶„ì„ ìš”ì²­
ìœ„ ë°ì´í„°ì™€ **ë¶„ì„ ê°€ì´ë“œë¼ì¸**ì„ ë°”íƒ•ìœ¼ë¡œ, íŠ¹íˆ **`recent_log_warnings_and_errors`ì— í¬í•¨ëœ ì‹œìŠ¤í…œ ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ì£¼ì˜ ê¹Šê²Œ ë¶„ì„**í•˜ì—¬ ë‹¤ìŒ JSON í˜•ì‹ì— ë§ì¶° ì¢…í•©ì ì¸ ì‹œìŠ¤í…œ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.
- ë¡œê·¸ì—ì„œ ë°œê²¬ëœ êµ¬ì²´ì ì¸ ì˜¤ë¥˜ë‚˜ ê²½ê³ ë¥¼ `critical_issues` ë˜ëŠ” `warnings` í•­ëª©ì— ë°˜ë“œì‹œ ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤.
- `recommendations`ì˜ ê° í•­ëª©ì„ ì‘ì„±í•  ë•Œ, ì–´ë–¤ ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ê·¼ê±°ë¡œ í•´ë‹¹ ê¶Œì¥ì‚¬í•­ì„ ë§Œë“¤ì—ˆëŠ”ì§€ `related_logs` í•„ë“œì— ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.

```json
{{
  "system_status": "ì •ìƒ|ì£¼ì˜|ìœ„í—˜",
  "overall_health_score": 100,
  "critical_issues": ["ë¶„ì„ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ì‹ë³„ëœ ì‹¬ê°í•œ ë¬¸ì œë“¤ì˜ êµ¬ì²´ì ì¸ ì„¤ëª…"],
  "warnings": ["ì£¼ì˜ê°€ í•„ìš”í•œ ì‚¬í•­ë“¤"],
  "recommendations": [
    {{
      "priority": "ë†’ìŒ|ì¤‘ê°„|ë‚®ìŒ",
      "category": "ì„±ëŠ¥|ë³´ì•ˆ|ì•ˆì •ì„±|ìœ ì§€ë³´ìˆ˜",
      "issue": "ë¬¸ì œì  ì„¤ëª…",
      "solution": "êµ¬ì²´ì ì¸ í•´ê²° ë°©ì•ˆ",
      "related_logs": ["ì´ ê¶Œì¥ì‚¬í•­ì˜ ê·¼ê±°ê°€ ëœ íŠ¹ì • ë¡œê·¸ ë©”ì‹œì§€(ë“¤)"]
    }}
  ],
  "summary": "ì „ì²´ì ì¸ ì‹œìŠ¤í…œ ìƒíƒœì™€ ì£¼ìš” ê¶Œì¥ì‚¬í•­ì— ëŒ€í•œ ì¢…í•© ìš”ì•½"
}}
```

**ì¤‘ìš”**: ë‹¹ì‹ ì˜ ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ„ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ ì—†ì´, `{{`ë¡œ ì‹œì‘í•´ì„œ `}}`ë¡œ ëë‚˜ëŠ” ìˆœìˆ˜í•œ JSON ê°ì²´ë§Œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤. `related_logs` í•„ë“œëŠ” ê·¼ê±°ê°€ ëœ ë¡œê·¸ê°€ ì—†ì„ ê²½ìš° ë¹ˆ ë°°ì—´ `[]`ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
"""
        return prompt

    def _parse_ai_response(self, ai_response: str) -> Any:
        """AI ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ ë° íŒŒì‹±. ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ."""
        print("AI ì‘ë‹µ íŒŒì‹± ì¤‘...")
        
        if not ai_response or not ai_response.strip():
            raise ValueError("AI ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

        refusal_patterns = [
            "i'm sorry", "i cannot", "i can't", "i am unable", 
            "ì£„ì†¡í•©ë‹ˆë‹¤", "í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        ]
        if any(pattern in ai_response.lower() for pattern in refusal_patterns):
            raise ValueError(f"LLMì´ ìš”ì²­ ì²˜ë¦¬ë¥¼ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤. (ì‘ë‹µ: '{ai_response.strip()}')")

        try:
            cleaned_response = re.sub(r'^```(json)?\s*|\s*```$', '', ai_response.strip())
            start = cleaned_response.find('{')
            end = cleaned_response.rfind('}')
            
            if start == -1 or end == -1 or end < start:
                raise ValueError("ì‘ë‹µì—ì„œ ìœ íš¨í•œ JSON ê°ì²´({{ ... }})ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            json_str = cleaned_response[start:end+1]
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            error_message = f"AI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}.\n--- ì›ë³¸ ì‘ë‹µ ---\n{ai_response}\n----------------"
            print(error_message)
            raise ValueError(error_message)
        except ValueError as e:
            error_message = f"AI ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}.\n--- ì›ë³¸ ì‘ë‹µ ---\n{ai_response}\n----------------"
            print(error_message)
            raise ValueError(error_message)

    def fetch_security_news(self, sos_data: Dict[str, Any]) -> List[Dict[str, str]]:
        """
        Red Hat APIë¥¼ í†µí•´ ì‹œìŠ¤í…œì— ê°€ì¥ ì¤‘ìš”í•œ CVEë¥¼ ì„ ë³„í•©ë‹ˆë‹¤.
        LLMì˜ Web Search ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ìµœì‹  ë™í–¥ì„ ë°˜ì˜í•©ë‹ˆë‹¤.
        """
        print("ìµœì‹  RHEL ë³´ì•ˆ ë‰´ìŠ¤ ì¡°íšŒ ë° ë¶„ì„ ì‹œì‘...")
        
        installed_packages_full = sos_data.get("installed_packages", [])
        if not installed_packages_full:
            reason = "sosreportì— ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ì •ë³´(installed-rpms)ê°€ ì—†ì–´ CVE ì—°ê´€ì„±ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            print(f"âš ï¸ {reason}")
            return [{"reason": reason}]

        try:
            installed_packages_map = {re.sub(r'-[\d.:].*', '', pkg): pkg for pkg in installed_packages_full}
            installed_package_names_only = set(installed_packages_map.keys())
            kernel_version = sos_data.get("system_info", {}).get("kernel", "N/A")

            print(f"ë¶„ì„ ëŒ€ìƒ ì‹œìŠ¤í…œ ì»¤ë„ ë²„ì „: {kernel_version}")
            print(f"ë¶„ì„ ëŒ€ìƒ ì‹œìŠ¤í…œì˜ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ {len(installed_packages_full)}ê°œë¥¼ DBí™”í•˜ì—¬ ì°¸ê³ í•©ë‹ˆë‹¤.")

            api_url = "https://access.redhat.com/hydra/rest/securitydata/cve.json"
            print(f"Red Hat CVE API í˜¸ì¶œ: {api_url}")
            response = requests.get(api_url, timeout=120)
            if response.status_code != 200:
                print(f"âš ï¸ Red Hat CVE API ì¡°íšŒ ì‹¤íŒ¨ (HTTP {response.status_code})")
                return [{"reason": f"Red Hat CVE API ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ (HTTP {response.status_code})."}]

            all_cves = response.json()
            print(f"ì´ {len(all_cves)}ê°œì˜ CVE ë°ì´í„°ë¥¼ Red Hatì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
            
            now = datetime.now()
            start_date = now - timedelta(days=180)
            
            package_cve_map = {}
            severity_order = {"critical": 2, "important": 1, "moderate": 0, "low": -1}

            for cve in all_cves:
                public_date_str = cve.get('public_date')
                if not public_date_str: continue
                
                try:
                    cve_date = datetime.fromisoformat(public_date_str.replace('Z', '+00:00')).replace(tzinfo=None)
                except ValueError:
                    continue
                
                severity_value = cve.get('severity')
                severity = severity_value.lower() if isinstance(severity_value, str) else 'low'

                if not (start_date <= cve_date <= now and severity in ["critical", "important"]):
                    continue
                
                cve_affected_packages = cve.get('affected_packages', [])
                for pkg_str in cve_affected_packages:
                    pkg_name_match = re.match(r'^([a-zA-Z0-9_.+-]+)-', pkg_str)
                    if pkg_name_match:
                        pkg_name = pkg_name_match.group(1)
                        if pkg_name in installed_package_names_only:
                            current_severity = severity_order.get(severity, -1)
                            existing_cve = package_cve_map.get(pkg_name)
                            
                            if not existing_cve or current_severity > severity_order.get(existing_cve.get('severity', 'low').lower(), -1):
                                cve['matched_package'] = installed_packages_map[pkg_name]
                                package_cve_map[pkg_name] = cve
            
            system_relevant_cves = list(package_cve_map.values())

            if not system_relevant_cves:
                reason = "ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ì£¼ëŠ” ìµœì‹  ë³´ì•ˆ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
                print(reason)
                return [{"reason": reason}]

            print(f"ì‹œìŠ¤í…œ ê´€ë ¨ CVE {len(system_relevant_cves)}ê°œë¥¼ 1ì°¨ ì„ ë³„í–ˆìŠµë‹ˆë‹¤. (íŒ¨í‚¤ì§€ë‹¹ 1ê°œ)")
            
            cve_identifiers = [cve['CVE'] for cve in system_relevant_cves]
            packages_str = "\n- ".join(list(installed_packages_full)[:50]) + ("..." if len(installed_packages_full) > 50 else "")

            selection_prompt = f"""
[ì‹œìŠ¤í…œ ì•ˆë‚´]
ë‹¹ì‹ ì€ Red Hat Enterprise Linux(RHEL)ë¥¼ ì „ë¬¸ìœ¼ë¡œ ë‹¤ë£¨ëŠ” 'ì‹œë‹ˆì–´ ë³´ì•ˆ ìœ„í˜‘ ë¶„ì„ê°€'ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ RHEL ê´€ë ¨ ë³´ì•ˆ ì·¨ì•½ì  ëª©ë¡ì„ ë¶„ì„í•˜ì—¬, íŠ¹ì • ì‹œìŠ¤í…œì— ê°€ì¥ ì‹œê¸‰í•˜ê³  ì¤‘ìš”í•œ CVEë¥¼ **ìµœëŒ€ 10ê°œ**ê¹Œì§€ ì„ ì •í•˜ê³ , ê·¸ ì„ ë³„ ì´ìœ ë¥¼ ëª…í™•íˆ ê¸°ë¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ì„ ë³„ ê³¼ì •ì—ì„œ í•„ìš”í•˜ë‹¤ë©´ **Web Search**ë¥¼ í™œì„±í™”í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  íŒë‹¨ì— ë°˜ì˜í•˜ì‹­ì‹œì˜¤.

[ë¶„ì„ ëŒ€ìƒ ì‹œìŠ¤í…œ ì •ë³´]
- **ì»¤ë„ ë²„ì „:** {kernel_version}
- **ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ëª©ë¡ (ì¼ë¶€):**
- {packages_str}

[ì„ ë³„ ê¸°ì¤€]
1.  **ìµœì‹  ë™í–¥ ë° ì‹¤ì œ ìœ„í˜‘(Web Search í™œìš©):** Web Searchë¥¼ í†µí•´ ìµœì‹  ë³´ì•ˆ ë™í–¥, ê³µê°œëœ ê³µê²© ì½”ë“œ(Exploit) ìœ ë¬´, ì‹¤ì œ ê³µê²©(In-the-wild) ì‚¬ë¡€ ë“±ì„ íŒŒì•…í•˜ì—¬ ìœ„í—˜ë„ê°€ ë†’ë‹¤ê³  íŒë‹¨ë˜ëŠ” CVEë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.
2.  **ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—°ê´€ì„±:** ì£¼ì–´ì§„ ëª©ë¡ì˜ ëª¨ë“  CVEëŠ” ì´ë¯¸ ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ì™€ ì—°ê´€ì„±ì´ í™•ì¸ëœ ìƒíƒœì…ë‹ˆë‹¤.
3.  **ì˜í–¥ë°›ëŠ” í•µì‹¬ ì»´í¬ë„ŒíŠ¸:** `kernel`, `glibc`, `openssl`, `openssh`, `systemd` ë“± RHEL ì‹œìŠ¤í…œì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ì— ì˜í–¥ì„ ì£¼ëŠ” ì·¨ì•½ì  severityê°€ (important, critical)ì„ ìš°ì„ ì ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤.

[ì…ë ¥ ë°ì´í„°]
ë¶„ì„ ëŒ€ìƒ CVE ëª©ë¡ (ì‹œìŠ¤í…œ ê´€ë ¨ì„± í™•ì¸ë¨): {', '.join(cve_identifiers)}

[ì¶œë ¥ ì§€ì‹œ]
ìœ„ ì„ ë³„ ê¸°ì¤€ì„ ì¢…í•©ì ìœ¼ë¡œ ì ìš©í•˜ì—¬ ì„ ì •í•œ **ìµœëŒ€ 10ê°œ**ì˜ CVEì— ëŒ€í•œ ì •ë³´ë¥¼ ì•„ë˜ JSON í˜•ì‹ì— ë§ì¶° **ì˜¤ì§ JSON ê°ì²´ë§Œ** ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
- `cve_id`: **ë°˜ë“œì‹œ [ì…ë ¥ ë°ì´í„°]ì— ì¡´ì¬í•˜ëŠ” CVE ID ì¤‘ì—ì„œë§Œ** ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.
- `selection_reason`: ì™œ ì´ CVEë¥¼ ì„ íƒí–ˆëŠ”ì§€ ì„ ë³„ ê¸°ì¤€(íŠ¹íˆ ì›¹ ê²€ìƒ‰ì„ í†µí•´ íŒŒì•…í•œ ìµœì‹  ë™í–¥ ë° ì‹¤ì œ ìœ„í˜‘)ì— ê·¼ê±°í•˜ì—¬ **í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ** ê¸°ìˆ í•´ì•¼ í•©ë‹ˆë‹¤.

```json
{{
  "cve_selection": [
    {{
      "cve_id": "CVE-XXXX-XXXX",
      "selection_reason": "ì´ CVEë¥¼ ì„ ë³„í•œ êµ¬ì²´ì ì¸ ì´ìœ  (ì˜ˆ: ìµœê·¼ ê³µê²© ì½”ë“œê°€ ê³µê°œë˜ì—ˆìœ¼ë©°, ì‹œìŠ¤í…œì˜ OpenSSL íŒ¨í‚¤ì§€ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ì¤Œ)"
    }}
  ]
}}
```
"""
            
            selection_result = self.perform_ai_analysis(selection_prompt, is_news_request=True)
            
            top_cves_data = []
            if isinstance(selection_result, dict) and 'cve_selection' in selection_result and selection_result['cve_selection']:
                llm_log_path = self.output_dir / "llm_security_news.log"
                selected_cves_from_llm = selection_result['cve_selection']
                original_cves_map = {cve['CVE']: cve for cve in system_relevant_cves}
                
                with open(llm_log_path, 'a', encoding='utf-8') as f:
                    f.write("\n\n--- CVE SELECTION & VALIDATION ---\n")
                    for item in selected_cves_from_llm:
                        cve_id = item.get('cve_id')
                        reason = item.get('selection_reason', 'No reason provided.')
                        
                        if cve_id and cve_id in original_cves_map:
                            log_entry = f"- [VALID] {cve_id}: {reason}\n"
                            f.write(log_entry)
                            print(f"ğŸ“ ë¡œê·¸ ê¸°ë¡ (ìœ íš¨): {cve_id} ì„ ë³„ ì´ìœ ")
                            top_cves_data.append(original_cves_map[cve_id])
                        else:
                            log_entry = f"- [INVALID/HALLUCINATED] ID: {cve_id}, Reason: {reason}\n"
                            f.write(log_entry)
                            print(f"âš ï¸ ê²½ê³ : AIê°€ ìƒì„±í•œ ìœ íš¨í•˜ì§€ ì•Šì€ CVE ID({cve_id})ë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤.")
            
            if not top_cves_data:
                print("âš ï¸ LLMì´ ì¤‘ìš” CVEë¥¼ ì„ ì •í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ìƒìœ„ CVEë¥¼ ì„ íƒí•©ë‹ˆë‹¤.")
                top_cves_data = sorted(system_relevant_cves, key=lambda x: (severity_order.get(x.get('severity', 'low').lower(), -1), x.get('public_date')), reverse=True)[:10]

            # --- ìµœëŒ€ 10ê°œ ë³´ì™„ ë¡œì§ ---
            if len(top_cves_data) < 10:
                print(f"AIê°€ {len(top_cves_data)}ê°œì˜ CVEë§Œ ì„ ì •í–ˆìŠµë‹ˆë‹¤. ëª©ë¡ì„ ë³´ì¶©í•©ë‹ˆë‹¤.")
                selected_cve_ids = {cve['CVE'] for cve in top_cves_data}
                remaining_cves = [cve for cve in system_relevant_cves if cve['CVE'] not in selected_cve_ids]
                
                sorted_remaining = sorted(remaining_cves, key=lambda x: (severity_order.get(x.get('severity', 'low').lower(), -1), x.get('public_date')), reverse=True)
                
                needed = 10 - len(top_cves_data)
                top_cves_data.extend(sorted_remaining[:needed])


            processing_data = [{"cve_id": cve['CVE'], "description": cve.get('bugzilla_description', 'ìš”ì•½ ì •ë³´ ì—†ìŒ')} for cve in top_cves_data]

            processing_prompt = f"""
[ì‹œìŠ¤í…œ ì•ˆë‚´]
ë‹¹ì‹ ì€ Red Hat Enterprise Linux(RHEL) ë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ ê° CVEì˜ ì˜ë¬¸ ê¸°ìˆ  ì„¤ëª…ì„ ë¶„ì„í•˜ì—¬, ì‹œìŠ¤í…œ ê´€ë¦¬ìê°€ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•µì‹¬ ë‚´ìš©ê³¼ ì‹œìŠ¤í…œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì¤‘ì‹¬ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ìš”ì•½ ë° ì„¤ëª…í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

[ì…ë ¥ ë°ì´í„°]
```json
{json.dumps(processing_data, indent=2, ensure_ascii=False)}
```

[ì¶œë ¥ ì§€ì‹œ]
ì•„ë˜ JSON í˜•ì‹ì— ë§ì¶°, ê° CVEì— ëŒ€í•œ ì•Œê¸° ì‰¬ìš´ ìš”ì•½ ì„¤ëª…ì„ í¬í•¨í•˜ì—¬ **ì˜¤ì§ JSON ê°ì²´ë§Œ** ì¶œë ¥í•˜ì‹­ì‹œì˜¤. ë‹¨ìˆœ ë²ˆì—­ì´ ì•„ë‹Œ, ìœ„í˜‘ì˜ ë³¸ì§ˆê³¼ ì ì¬ì  ì˜í–¥ì„ ëª…í™•íˆ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.

```json
{{
  "processed_cves": [
    {{
      "cve_id": "CVE-XXXX-XXXX",
      "translated_description": "í•´ë‹¹ CVEì˜ í•µì‹¬ ìœ„í˜‘ê³¼ ì‹œìŠ¤í…œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ëŒ€í•œ ì‰½ê³  ëª…í™•í•œ í•œêµ­ì–´ ìš”ì•½ ì„¤ëª…"
    }}
  ]
}}
```
"""

            processed_result = self.perform_ai_analysis(processing_prompt, is_news_request=True)

            final_cves = []
            if isinstance(processed_result, dict) and 'processed_cves' in processed_result:
                processed_map = {item['cve_id']: item for item in processed_result['processed_cves']}
                for cve_data in top_cves_data:
                    cve_id = cve_data['CVE']
                    if cve_id in processed_map:
                        processed_info = processed_map[cve_id]
                        cve_date_str = cve_data.get('public_date', '')
                        if cve_date_str:
                            try:
                                cve_data['public_date'] = datetime.fromisoformat(cve_date_str.replace('Z', '+00:00')).strftime('%y/%m/%d')
                            except ValueError:
                                pass
                        
                        cve_data['bugzilla_description'] = processed_info.get('translated_description', cve_data['bugzilla_description'])
                        final_cves.append(cve_data)
                        print(f"âœ… ë³´ì•ˆ ë‰´ìŠ¤ ì²˜ë¦¬ ì™„ë£Œ: {cve_id}")
            else:
                print("âš ï¸ LLMì˜ ë²ˆì—­ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ë¡œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                final_cves = top_cves_data

            print("âœ… ë³´ì•ˆ ë‰´ìŠ¤ ì¡°íšŒ ë° ì²˜ë¦¬ ì™„ë£Œ.")
            return final_cves

        except Exception as e:
            print(f"âŒ ë³´ì•ˆ ë‰´ìŠ¤ ì¡°íšŒ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return [{"reason": f"ë³´ì•ˆ ë‰´ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"}]

    def create_performance_graphs(self, perf_data: Dict[str, List[Dict[str, Any]]]) -> Dict[str, str]:
        """ì„±ëŠ¥ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ê³  base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not plt:
            print("âš ï¸ ê·¸ë˜í”„ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤. 'matplotlib' ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.")
            return {}

        print("ì„±ëŠ¥ ê·¸ë˜í”„ ìƒì„± ì¤‘...")
        graphs = {}
        
        # CPU ê·¸ë˜í”„
        if perf_data.get('cpu'):
            cpu_data = perf_data['cpu']
            timestamps = [d['timestamp'] for d in cpu_data]
            user = [d['user'] for d in cpu_data]
            system = [d['system'] for d in cpu_data]
            iowait = [d['iowait'] for d in cpu_data]
            idle = [d['idle'] for d in cpu_data]
            
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.stackplot(timestamps, user, system, iowait, idle, 
                         labels=['User %', 'System %', 'I/O Wait %', 'Idle %'], 
                         colors=['#007bff', '#ffc107', '#dc3545', '#28a745'])
            ax.set_title('CPU ì‚¬ìš©ë¥  (%)', fontsize=16)
            ax.set_xlabel('ì‹œê°„', fontsize=12)
            ax.set_ylabel('ì‚¬ìš©ë¥  (%)', fontsize=12)
            ax.legend(loc='upper left')
            ax.grid(True, linestyle='--', alpha=0.6)
            plt.xticks(rotation=45)
            plt.tight_layout()
            
            buf = io.BytesIO()
            fig.savefig(buf, format='png')
            graphs['cpu_graph'] = base64.b64encode(buf.getvalue()).decode('utf-8')
            plt.close(fig)

        # ë©”ëª¨ë¦¬ ê·¸ë˜í”„
        if perf_data.get('memory'):
            mem_data = perf_data['memory']
            timestamps = [d['timestamp'] for d in mem_data]
            mem_used = [d['memused_percent'] for d in mem_data]
            
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.plot(timestamps, mem_used, label='ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)', color='#dc3545', marker='o', linestyle='-')
            ax.set_title('ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)', fontsize=16)
            ax.set_xlabel('ì‹œê°„', fontsize=12)
            ax.set_ylabel('ì‚¬ìš©ë¥  (%)', fontsize=12)
            ax.legend(loc='upper left')
            ax.grid(True, linestyle='--', alpha=0.6)
            plt.xticks(rotation=45)
            plt.tight_layout()

            buf = io.BytesIO()
            fig.savefig(buf, format='png')
            graphs['memory_graph'] = base64.b64encode(buf.getvalue()).decode('utf-8')
            plt.close(fig)

        # ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„
        if perf_data.get('network'):
            net_data = perf_data['network']
            timestamps = [d['timestamp'] for d in net_data]
            rxkB = [d['rxkB'] for d in net_data]
            txkB = [d['txkB'] for d in net_data]

            fig, ax = plt.subplots(figsize=(12, 6))
            ax.plot(timestamps, rxkB, label='ìˆ˜ì‹  (kB/s)', color='#17a2b8', marker='^', linestyle='-')
            ax.plot(timestamps, txkB, label='ì†¡ì‹  (kB/s)', color='#6f42c1', marker='v', linestyle='-')
            ax.set_title('ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ (kB/s)', fontsize=16)
            ax.set_xlabel('ì‹œê°„', fontsize=12)
            ax.set_ylabel('kB/s', fontsize=12)
            ax.legend(loc='upper left')
            ax.grid(True, linestyle='--', alpha=0.6)
            plt.xticks(rotation=45)
            plt.tight_layout()

            buf = io.BytesIO()
            fig.savefig(buf, format='png')
            graphs['network_graph'] = base64.b64encode(buf.getvalue()).decode('utf-8')
            plt.close(fig)

        # ë””ìŠ¤í¬ ê·¸ë˜í”„
        if perf_data.get('disk'):
            disk_data = perf_data['disk']
            timestamps = [d['timestamp'] for d in disk_data]
            read_kB = [d['read_kB'] for d in disk_data]
            write_kB = [d['write_kB'] for d in disk_data]
            util_percent = [d['util_percent'] for d in disk_data]

            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)
            
            ax1.plot(timestamps, read_kB, label='ì½ê¸° (kB/s)', color='#28a745', marker='>', linestyle='-')
            ax1.plot(timestamps, write_kB, label='ì“°ê¸° (kB/s)', color='#fd7e14', marker='<', linestyle='-')
            ax1.set_title('ë””ìŠ¤í¬ I/O (kB/s)', fontsize=14)
            ax1.set_ylabel('kB/s', fontsize=12)
            ax1.legend(loc='upper left')
            ax1.grid(True, linestyle='--', alpha=0.6)

            ax2.plot(timestamps, util_percent, label='ì‚¬ìš©ë¥  (%)', color='#6610f2', marker='s', linestyle='-')
            ax2.set_title('ë””ìŠ¤í¬ ì‚¬ìš©ë¥  (%)', fontsize=14)
            ax2.set_xlabel('ì‹œê°„', fontsize=12)
            ax2.set_ylabel('ì‚¬ìš©ë¥  (%)', fontsize=12)
            ax2.legend(loc='upper left')
            ax2.grid(True, linestyle='--', alpha=0.6)
            
            plt.xticks(rotation=45)
            plt.tight_layout()

            buf = io.BytesIO()
            fig.savefig(buf, format='png')
            graphs['disk_graph'] = base64.b64encode(buf.getvalue()).decode('utf-8')
            plt.close(fig)

        print("âœ… ì„±ëŠ¥ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ.")
        return graphs

    def create_html_report(self, analysis_result: Dict[str, Any], sos_data: Dict[str, Any], graphs: Dict[str, str], output_dir: str, original_file: str) -> str:
        """ë¶„ì„ ê²°ê³¼ì™€ ê·¸ë˜í”„ë¥¼ ë°”íƒ•ìœ¼ë¡œ HTML ë³´ê³ ì„œ ìƒì„±"""
        print("HTML ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        base_name = Path(original_file).stem.replace('.tar', '')
        report_file = Path(output_dir) / f"{base_name}_report.html"

        status = html.escape(analysis_result.get('system_status', 'N/A'))
        score = analysis_result.get('overall_health_score', 'N/A')
        summary = html.escape(analysis_result.get('summary', 'ì •ë³´ ì—†ìŒ')).replace('\n', '<br>')
        critical_issues = analysis_result.get('critical_issues', [])
        warnings = analysis_result.get('warnings', [])
        recommendations = analysis_result.get('recommendations', [])
        
        system_info = sos_data.get('system_info', {})
        ip4_details = sos_data.get('ip4_details', [])
        network_details = sos_data.get('network_details', {})
        storage_info = sos_data.get('storage', [])
        process_stats = sos_data.get('process_stats', {})
        failed_services = sos_data.get('failed_services', [])
        security_news = sos_data.get('security_news', [])

        status_colors = {"ì •ìƒ": "#28a745", "ì£¼ì˜": "#ffc107", "ìœ„í—˜": "#dc3545"}
        status_color = status_colors.get(status, "#6c757d")

        ip4_details_rows = ""
        if not ip4_details:
            ip4_details_rows = "<tr><td colspan='6' style='text-align:center;'>ë°ì´í„° ì—†ìŒ</td></tr>"
        else:
            for item in ip4_details:
                state_val = item.get('state', 'unknown').lower()
                if 'up' in state_val:
                    state_html = '<td style="color: green; font-weight: bold;">ğŸ”› UP</td>'
                elif 'down' in state_val:
                    state_html = '<td style="color: grey;">ğŸ“´ DOWN</td>'
                else:
                    state_html = f"<td>â“ {html.escape(state_val.upper())}</td>"
                
                ip4_details_rows += f"""
                    <tr>
                        <td>{html.escape(item.get('iface', 'N/A'))}</td>
                        <td>{html.escape(item.get('master', 'N/A'))}</td>
                        <td>{html.escape(item.get('mac', 'N/A'))}</td>
                        <td>{html.escape(item.get('mtu', 'N/A'))}</td>
                        {state_html}
                        <td>{html.escape(item.get('ipv4', 'N/A'))}</td>
                    </tr>
                """

        def create_table_rows(data_list, headers):
            rows = ""
            if not data_list:
                return f"<tr><td colspan='{len(headers)}' style='text-align:center;'>ë°ì´í„° ì—†ìŒ</td></tr>"
            
            if isinstance(data_list, list) and len(data_list) == 1 and 'reason' in data_list[0]:
                reason_text = html.escape(data_list[0]['reason'])
                return f"<tr><td colspan='{len(headers)}' style='text-align:center;'>{reason_text}</td></tr>"

            for item in data_list:
                rows += "<tr>"
                for header in headers:
                    if header == 'CVE' and isinstance(item.get(header), str):
                        cve_id = html.escape(item.get(header))
                        rows += f'<td><a href="https://access.redhat.com/security/cve/{cve_id}" target="_blank">{cve_id}</a></td>'
                    else:
                        rows += f"<td>{html.escape(str(item.get(header, 'N/A')))}</td>"
                rows += "</tr>"
            return rows
        
        def create_security_news_rows(news_list):
            rows = ""
            if not news_list:
                return "<tr><td colspan='4' style='text-align:center;'>ë°ì´í„° ì—†ìŒ</td></tr>"
            
            if isinstance(news_list, list) and len(news_list) == 1 and 'reason' in news_list[0]:
                reason_text = html.escape(news_list[0]['reason'])
                return f"<tr><td colspan='4' style='text-align:center;'>{reason_text}</td></tr>"

            for item in news_list:
                cve_id = html.escape(item.get('CVE', 'N/A'))
                severity = item.get('severity', '').lower()
                matched_package = html.escape(item.get('matched_package', 'N/A'))

                severity_html = ''
                if severity == 'critical':
                    severity_html = f'<td style="text-align:center;"><div class="tooltip" style="font-size: 1.5em;">ğŸ”¥<span class="tooltiptext">íŒ¨í‚¤ì§€: {matched_package}</span></div></td>'
                elif severity == 'important':
                    severity_html = f'<td style="text-align:center;"><div class="tooltip" style="font-size: 1.5em;">âš ï¸<span class="tooltiptext">íŒ¨í‚¤ì§€: {matched_package}</span></div></td>'
                else:
                    severity_html = f"<td>{html.escape(item.get('severity', 'N/A'))}</td>"

                rows += f"""
                    <tr>
                        <td><a href="https://access.redhat.com/security/cve/{cve_id}" target="_blank">{cve_id}</a></td>
                        {severity_html}
                        <td>{html.escape(item.get('public_date', 'N/A'))}</td>
                        <td>{html.escape(item.get('bugzilla_description', 'N/A'))}</td>
                    </tr>
                """
            return rows
        
        def create_recommendation_rows(recommendations_list):
            rows = ""
            if not recommendations_list:
                return "<tr><td colspan='4' style='text-align:center;'>ë°ì´í„° ì—†ìŒ</td></tr>"
            
            for item in recommendations_list:
                priority = html.escape(str(item.get('priority', 'N/A')))
                category = html.escape(str(item.get('category', 'N/A')))
                issue = html.escape(str(item.get('issue', 'N/A')))
                solution = html.escape(str(item.get('solution', 'N/A')))
                related_logs = item.get('related_logs', [])

                issue_html = issue
                if related_logs:
                    logs_html = html.escape('\n'.join(related_logs))
                    issue_html += f"""
                        <div class="tooltip">
                            <span class="log-icon">ğŸ’¬</span>
                            <span class="tooltiptext">{logs_html}</span>
                        </div>
                    """

                rows += f"""
                    <tr>
                        <td>{priority}</td>
                        <td>{category}</td>
                        <td>{issue_html}</td>
                        <td>{solution}</td>
                    </tr>
                """
            return rows

        def create_list_table(items: List[str], empty_message: str) -> str:
            if not items:
                return f"<tr><td style='text-align:center;'>{html.escape(empty_message)}</td></tr>"
            
            rows = ""
            for item in items:
                rows += f"<tr><td>{html.escape(item)}</td></tr>"
            return rows

        graph_html = ""
        if graphs:
            graph_html += '<div class="section"><h2>ğŸ“Š ì„±ëŠ¥ ë¶„ì„ ê·¸ë˜í”„</h2>'
            if 'cpu_graph' in graphs: graph_html += f'<h3>CPU ì‚¬ìš©ë¥ </h3><img src="data:image/png;base64,{graphs["cpu_graph"]}" alt="CPU Graph" style="width:100%; max-width: 800px; display: block; margin: auto;">'
            if 'memory_graph' in graphs: graph_html += f'<h3>ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ </h3><img src="data:image/png;base64,{graphs["memory_graph"]}" alt="Memory Graph" style="width:100%; max-width: 800px; display: block; margin: auto;">'
            if 'network_graph' in graphs: graph_html += f'<h3>ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½</h3><img src="data:image/png;base64,{graphs["network_graph"]}" alt="Network Graph" style="width:100%; max-width: 800px; display: block; margin: auto;">'
            if 'disk_graph' in graphs: graph_html += f'<h3>ë””ìŠ¤í¬ I/O ë° ì‚¬ìš©ë¥ </h3><img src="data:image/png;base64,{graphs["disk_graph"]}" alt="Disk Graph" style="width:100%; max-width: 800px; display: block; margin: auto;">'
            graph_html += '</div>'
        
        netdev_rx_rows = ""
        netdev_tx_rows = ""
        netdev_data = network_details.get('netdev', [])
        for dev in netdev_data:
            rx_packets = dev.get('rx_packets', 0)
            rx_drop = dev.get('rx_drop', 0)
            rx_multicast = dev.get('rx_multicast', 0)
            rx_drop_pct = f"({int(rx_drop * 100 / rx_packets)}%)" if rx_packets > 0 else ""
            rx_multicast_pct = f"({int(rx_multicast * 100 / rx_packets)}%)" if rx_packets > 0 else ""
            netdev_rx_rows += f"<tr><td>{html.escape(dev['iface'])}</td><td>{dev['rx_bytes']:,}</td><td>{dev['rx_packets']:,}</td><td>{dev['rx_errs']}</td><td>{dev['rx_drop']} {rx_drop_pct}</td><td>{dev['rx_multicast']} {rx_multicast_pct}</td></tr>"
            netdev_tx_rows += f"<tr><td>{html.escape(dev['iface'])}</td><td>{dev['tx_bytes']:,}</td><td>{dev['tx_packets']:,}</td><td>{dev['tx_errs']}</td><td>{dev['tx_drop']}</td><td>{dev['tx_colls']}</td><td>{dev['tx_carrier']}</td></tr>"

        ethtool_rows = ""
        ethtool_data = network_details.get('ethtool', {})
        for iface, data in ethtool_data.items():
            ethtool_rows += f"<tr><td>{html.escape(iface)}</td><td>{html.escape(data.get('link', 'N/A'))}</td><td>{html.escape(data.get('speed', 'N/A'))}</td><td>{html.escape(data.get('driver', 'N/A'))}</td><td>{html.escape(data.get('firmware', 'N/A'))}</td></tr>"

        failed_services_rows = create_list_table(failed_services, "ì‹¤íŒ¨í•œ ì„œë¹„ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        critical_issues_rows = create_list_table(critical_issues, "ë°œê²¬ëœ ì‹¬ê°í•œ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")
        warnings_rows = create_list_table(warnings, "íŠ¹ë³„í•œ ê²½ê³  ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")

        html_template = f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI ë¶„ì„ ë³´ê³ ì„œ</title>
    <style>
        @import url('https://cdn.jsdelivr.net/gh/projectnoonnu/noonfonts_six@1.2/S-CoreDream.css');
        body {{ font-family: 'S-CoreDream', 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background-color: #f4f7f9; color: #333; margin: 0; padding: 20px; }}
        .container {{ max-width: 1000px; margin: auto; background: #fff; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); overflow: hidden; }}
        header {{ background-color: #343a40; color: white; padding: 20px; text-align: center; }}
        header h1 {{ margin: 0; font-size: 24px; }}
        .content {{ padding: 20px; }}
        .section {{ margin-bottom: 25px; }}
        .section h2 {{ 
            font-size: 20px;
            border-left: 5px solid #007bff; 
            padding-left: 10px; 
            margin-bottom: 15px; 
            color: #343a40; 
        }}
        .data-table {{
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
            table-layout: fixed;
            font-size: 14px;
            line-height: 1.6;
        }}
        .data-table th, .data-table td {{
            border: 1px solid #dee2e6;
            padding: 12px;
            text-align: left;
            word-wrap: break-word;
            vertical-align: top;
        }}
        .data-table thead th {{
            background-color: #f8f9fa;
            color: #495057;
            font-weight: 600;
            border-bottom: 2px solid #dee2e6;
        }}
        .data-table tbody th {{
            background-color: #f8f9fa;
            font-weight: 600;
            width: 25%;
        }}
        .data-table tbody tr:nth-child(even) {{
            background-color: #f8f9fa;
        }}
        .data-table tbody tr:hover {{
            background-color: #e9ecef;
        }}
        .ai-status {{ font-size: 1.2em; font-weight: bold; color: {status_color}; }}
        footer {{ text-align: center; padding: 15px; font-size: 12px; color: #888; background-color: #f4f7f9; }}
        
        .tooltip {{ position: relative; display: inline-block; cursor: pointer; }}
        .tooltip .tooltiptext {{
            visibility: hidden; width: 450px; max-height: 250px; overflow-y: auto; background-color: #333; color: #fff; text-align: left;
            border-radius: 6px; padding: 10px; position: absolute; z-index: 1; bottom: 125%;
            left: 50%; margin-left: -225px; opacity: 0; transition: opacity 0.3s; font-size: 12px;
            white-space: pre-wrap; word-break: break-all; box-shadow: 0 2px 5px rgba(0,0,0,0.2);
            font-family: 'Consolas', 'Monaco', monospace;
        }}
        .tooltip .tooltiptext::after {{
            content: ""; position: absolute; top: 100%; left: 50%; margin-left: -5px;
            border-width: 5px; border-style: solid; border-color: #333 transparent transparent transparent;
        }}
        .tooltip:hover .tooltiptext {{ visibility: visible; opacity: 1; }}
        .log-icon {{ font-size: 14px; margin-left: 5px; color: #007bff; }}
    </style>
</head>
<body>
    <div class="container">
        <header><h1>S-Core System Report</h1></header>
        <div class="content">
            
            <div class="section">
                <h2>â„¹ï¸ ì‹œìŠ¤í…œ ìš”ì•½</h2>
                <table class="data-table">
                    <tbody>
                        <tr><th>Hostname</th><td>{html.escape(system_info.get('hostname', 'N/A'))}</td></tr>
                        <tr><th>OS Version</th><td>{html.escape(system_info.get('os_version', 'N/A'))}</td></tr>
                        <tr><th>Kernel</th><td>{html.escape(system_info.get('kernel', 'N/A'))}</td></tr>
                        <tr><th>System Model</th><td>{html.escape(system_info.get('system_model', 'N/A'))}</td></tr>
                        <tr><th>CPU</th><td>{html.escape(system_info.get('cpu', 'N/A'))}</td></tr>
                        <tr><th>Memory</th><td>{html.escape(system_info.get('memory', 'N/A'))}</td></tr>
                        <tr><th>Uptime</th><td>{html.escape(system_info.get('uptime', 'N/A'))}</td></tr>
                        <tr><th>Last Boot</th><td>{html.escape(system_info.get('last_boot', 'N/A'))}</td></tr>
                    </tbody>
                </table>
            </div>

            {graph_html}

            <div class="section">
                <h2>ğŸŒ ë„¤íŠ¸ì›Œí¬ ì •ë³´</h2>
                <h3>IP4 ìƒì„¸ ì •ë³´</h3>
                <table class="data-table">
                    <thead><tr><th>Interface</th><th>Master IF</th><th>MAC Address</th><th>MTU</th><th>State</th><th>IPv4 Address</th></tr></thead>
                    <tbody>{ip4_details_rows}</tbody>
                </table>
                <h3>ë¼ìš°íŒ… í…Œì´ë¸”</h3>
                <table class="data-table">
                    <thead><tr><th>Destination</th><th>Gateway</th><th>Device</th><th>Source</th></tr></thead>
                    <tbody>{create_table_rows(system_info.get('routing_table', []), ['destination', 'gateway', 'device', 'source'])}</tbody>
                </table>
                <h3>ETHTOOL ìƒíƒœ</h3>
                <table class="data-table">
                    <thead><tr><th>Interface</th><th>Link</th><th>Speed</th><th>Driver</th><th>Firmware</th></tr></thead>
                    <tbody>{ethtool_rows}</tbody>
                </table>
                <h3>NETDEV í†µê³„ (Receive)</h3>
                <table class="data-table">
                    <thead><tr><th>Interface</th><th>RxBytes</th><th>RxPackets</th><th>RxErrs</th><th>RxDrop</th><th>RxMulticast</th></tr></thead>
                    <tbody>{netdev_rx_rows}</tbody>
                </table>
                <h3>NETDEV í†µê³„ (Transmit)</h3>
                <table class="data-table">
                    <thead><tr><th>Interface</th><th>TxBytes</th><th>TxPackets</th><th>TxErrs</th><th>TxDrop</th><th>TxColls</th><th>TxCarrier</th></tr></thead>
                    <tbody>{netdev_tx_rows}</tbody>
                </table>
                <h3>ì†Œì¼“ í†µê³„</h3>
                <pre style="background:#eee; padding:10px; border-radius:4px; word-wrap:break-word;">{html.escape(chr(10).join(network_details.get('sockstat', [])))}</pre>
                <h3>ë„¤íŠ¸ì›Œí¬ ë³¸ë”©</h3>
                <table class="data-table">
                    <thead><tr><th>Device</th><th>Mode</th><th>Slaves</th></tr></thead>
                    <tbody>{create_table_rows(network_details.get('bonding', []), ['device', 'mode', 'slaves'])}</tbody>
                </table>
            </div>
            <div class="section">
                <h2>ğŸ’¾ ìŠ¤í† ë¦¬ì§€ ë° íŒŒì¼ ì‹œìŠ¤í…œ</h2>
                <table class="data-table">
                    <thead><tr><th>Filesystem</th><th>Size</th><th>Used</th><th>Avail</th><th>Use%</th><th>Mounted on</th></tr></thead>
                    <tbody>{create_table_rows(storage_info, ['filesystem', 'size', 'used', 'avail', 'use%', 'mounted_on'])}</tbody>
                </table>
            </div>
            <div class="section">
                <h2>âš™ï¸ ë¦¬ì†ŒìŠ¤ ì‚¬ìš© í˜„í™©</h2>
                <h3>í”„ë¡œì„¸ìŠ¤ ìš”ì•½</h3>
                <table class="data-table">
                    <tbody><tr><th>Total Processes</th><td>{process_stats.get('total', 'N/A')}</td></tr></tbody>
                </table>
                <h3>Top Users of CPU & MEM</h3>
                <table class="data-table">
                    <thead><tr><th>USER</th><th>%CPU</th><th>%MEM</th><th>RSS</th></tr></thead>
                    <tbody>{create_table_rows(process_stats.get('by_user', []), ['user', 'cpu%', 'mem%', 'rss'])}</tbody>
                </table>
                <h3>Uninterruptible Sleep Processes ({len(process_stats.get('uninterruptible', []))})</h3>
                <table class="data-table">
                    <thead><tr><th>USER</th><th>PID</th><th>%CPU</th><th>%MEM</th><th>RSS</th><th>STAT</th><th>START</th><th>TIME</th><th>COMMAND</th></tr></thead>
                    <tbody>{create_table_rows(process_stats.get('uninterruptible', []), ['user', 'pid', 'cpu%', 'mem%', 'rss', 'stat', 'start', 'time', 'command'])}</tbody>
                </table>
                <h3>Zombie Processes ({len(process_stats.get('zombie', []))})</h3>
                <table class="data-table">
                    <thead><tr><th>USER</th><th>PID</th><th>%CPU</th><th>%MEM</th><th>RSS</th><th>STAT</th><th>START</th><th>TIME</th><th>COMMAND</th></tr></thead>
                    <tbody>{create_table_rows(process_stats.get('zombie', []), ['user', 'pid', 'cpu%', 'mem%', 'rss', 'stat', 'start', 'time', 'command'])}</tbody>
                </table>
                <h3>Top 5 Processes (CPU)</h3>
                <table class="data-table">
                    <colgroup><col style="width:10%"><col style="width:15%"><col style="width:15%"><col style="width:60%"></colgroup>
                    <thead><tr><th>PID</th><th>User</th><th>CPU %</th><th>Command</th></tr></thead>
                    <tbody>{create_table_rows(process_stats.get('top_cpu', []), ['pid', 'user', 'cpu%', 'command'])}</tbody>
                </table>
                <h3>Top 5 Processes (Memory)</h3>
                <table class="data-table">
                    <colgroup><col style="width:10%"><col style="width:15%"><col style="width:15%"><col style="width:60%"></colgroup>
                    <thead><tr><th>PID</th><th>User</th><th>RSS (KiB)</th><th>Command</th></tr></thead>
                    <tbody>{create_table_rows(process_stats.get('top_mem', []), ['pid', 'user', 'rss', 'command'])}</tbody>
                </table>
            </div>
            <div class="section">
                <h2>ğŸ”§ ì‹¤íŒ¨í•œ ì„œë¹„ìŠ¤ ({len(failed_services)}ê°œ)</h2>
                <table class="data-table">
                    <colgroup><col style="width:100%"></colgroup>
                    <thead><tr><th>ìƒì„¸ ë‚´ìš©</th></tr></thead>
                    <tbody>{failed_services_rows}</tbody>
                </table>
            </div>

            <!-- AI ë¶„ì„ ë° ë³´ì•ˆ ë‰´ìŠ¤ ì„¹ì…˜ (ìˆœì„œ ë³€ê²½ë¨) -->
            <div class="section">
                <h2>ğŸš¨ AI ë¶„ì„: ì‹¬ê°í•œ ì´ìŠˆ ({len(critical_issues)}ê°œ)</h2>
                <table class="data-table">
                    <colgroup><col style="width:100%"></colgroup>
                    <thead><tr><th>ìƒì„¸ ë‚´ìš©</th></tr></thead>
                    <tbody>{critical_issues_rows}</tbody>
                </table>
            </div>

            <div class="section">
                <h2>âš ï¸ AI ë¶„ì„: ê²½ê³  ì‚¬í•­ ({len(warnings)}ê°œ)</h2>
                <table class="data-table">
                    <colgroup><col style="width:100%"></colgroup>
                    <thead><tr><th>ìƒì„¸ ë‚´ìš©</th></tr></thead>
                    <tbody>{warnings_rows}</tbody>
                </table>
            </div>

            <div class="section">
                <h2>ğŸ’¡ AI ë¶„ì„: ê¶Œì¥ì‚¬í•­ ({len(recommendations)}ê°œ)</h2>
                <table class="data-table">
                    <colgroup><col style="width:10%"><col style="width:15%"><col style="width:35%"><col style="width:40%"></colgroup>
                    <thead><tr><th>ìš°ì„ ìˆœìœ„</th><th>ì¹´í…Œê³ ë¦¬</th><th>ë¬¸ì œì  ğŸ’¬</th><th>í•´ê²° ë°©ì•ˆ</th></tr></thead>
                    <tbody>{create_recommendation_rows(recommendations)}</tbody>
                </table>
            </div>
            
            <div class="section">
                <h2>ğŸ¤– AI ì¢…í•© ë¶„ì„</h2>
                <table class="data-table">
                    <colgroup><col style="width:20%"><col style="width:80%"></colgroup>
                    <tbody>
                        <tr><th>ì¢…í•© ìƒíƒœ</th><td><span class="ai-status">{status}</span></td></tr>
                        <tr><th>ê±´ê°•ë„ ì ìˆ˜</th><td>{score}/100</td></tr>
                        <tr><th>ìš”ì•½</th><td>{summary}</td></tr>
                    </tbody>
                </table>
            </div>

            <div class="section">
                <h2>ğŸ›¡ï¸ ë³´ì•ˆ ë‰´ìŠ¤ (ê°€ì¥ ì¤‘ìš”í•œ CVE ìµœëŒ€ 10ê°œ) <span style="font-size: 0.7em; font-weight: normal;">(ğŸ”¥ Critical, âš ï¸ Important)</span></h2>
                <table class="data-table">
                    <colgroup><col style="width:18%"><col style="width:10%"><col style="width:12%"><col style="width:60%"></colgroup>
                    <thead><tr><th>CVE ì‹ë³„ì</th><th>ì‹¬ê°ë„</th><th>ìƒì„±ì¼</th><th>ìœ„í˜‘ ë° ì˜í–¥ ìš”ì•½</th></tr></thead>
                    <tbody>{create_security_news_rows(security_news)}</tbody>
                </table>
                <p style="font-size: 12px; text-align: center;">ë³´ì•ˆ ì •ë³´ì— ëŒ€í•œ ìƒì„¸ ë‚´ìš©ì€ <a href="https://access.redhat.com/security/security-updates/security-advisories" target="_blank">Red Hat Security Advisories</a> ì‚¬ì´íŠ¸ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
            </div>

        </div>
        <footer>ë³´ê³ ì„œ ìƒì„± ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</footer>
    </div>
</body>
</html>"""
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(html_template)
            print(f"âœ… HTML ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_file}")
            return str(report_file)
        except Exception as e:
            print(f"âŒ HTML ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            raise

def win_safe_filter(member, path):
    """Windows ê²½ë¡œì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ ë¬¸ìë¥¼ '_'ë¡œ ë°”ê¾¸ëŠ” í•„í„° í•¨ìˆ˜"""
    member.name = member.name.replace(':', '_')
    return member

def decompress_sosreport(archive_path: str, extract_dir: str) -> str:
    """sosreport ì••ì¶• íŒŒì¼ì„ ì§€ì •ëœ ë””ë ‰í† ë¦¬ì— í•´ì œí•©ë‹ˆë‹¤."""
    print(f"ì••ì¶• íŒŒì¼ í•´ì œ ì¤‘: {archive_path}")
    try:
        with tarfile.open(archive_path, 'r:*') as tar:
            if sys.platform == "win32":
                tar.extractall(path=extract_dir, filter=win_safe_filter)
            else:
                tar.extractall(path=extract_dir)
        print(f"âœ… ì••ì¶• í•´ì œ ì™„ë£Œ: {extract_dir}")
        return extract_dir
    except tarfile.TarError as e:
        raise Exception(f"ì••ì¶• íŒŒì¼ í•´ì œ ì‹¤íŒ¨: {e}")

def rmtree_onerror(func, path, exc_info):
    """shutil.rmtreeë¥¼ ìœ„í•œ ì˜¤ë¥˜ í•¸ë“¤ëŸ¬."""
    if isinstance(exc_info[1], PermissionError):
        try:
            os.chmod(path, 0o777)
            func(path)
        except Exception as e:
            print(f"onerror í•¸ë“¤ëŸ¬ì—ì„œë„ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {path}, ì˜¤ë¥˜: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='sosreport ì••ì¶• íŒŒì¼ AI ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„± ë„êµ¬', formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('sosreport_archive', nargs='?', help='ë¶„ì„í•  sosreport ì••ì¶• íŒŒì¼ ê²½ë¡œ (.tar.xz, .tar.gz ë“±)')
    parser.add_argument('--llm-url', required=True, help='LLM ì„œë²„ì˜ ê¸°ë³¸ URL')
    parser.add_argument('--endpoint-path', default='/v1/chat/completions', help='APIì˜ Chat Completions ì—”ë“œí¬ì¸íŠ¸ ê²½ë¡œ')
    parser.add_argument('--model', help='ì‚¬ìš©í•  LLM ëª¨ë¸ ì´ë¦„ (list-models ì‚¬ìš© ì‹œ ë¶ˆí•„ìš”)')
    parser.add_argument('--api-token', help='API ì¸ì¦ í† í°. LLM_API_TOKEN í™˜ê²½ ë³€ìˆ˜ë¡œë„ ì„¤ì • ê°€ëŠ¥')
    parser.add_argument('--output', '-o', default='output', help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: output)')
    parser.add_argument('--no-html', action='store_true', help='HTML ë³´ê³ ì„œ ìƒì„±ì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.')
    parser.add_argument('--list-models', action='store_true', help='ì„œë²„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.')
    parser.add_argument('--test-only', action='store_true', help='LLM ì—°ê²° í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰ (ëª¨ë¸ ì´ë¦„ í•„ìš”)')
    
    args = parser.parse_args()
    api_token = args.api_token or os.getenv('LLM_API_TOKEN')
    
    if not plt:
        print("ê²½ê³ : 'matplotlib' ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê·¸ë˜í”„ ìƒì„± ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.", file=sys.stderr)
        print("'pip install matplotlib' ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.", file=sys.stderr)

    analyzer = AIAnalyzer(
        llm_url=args.llm_url, model_name=args.model,
        endpoint_path=args.endpoint_path, api_token=api_token,
        output_dir=args.output
    )

    if args.list_models:
        analyzer.list_available_models()
        sys.exit(0)

    if args.test_only:
        if not args.model: parser.error("--test-only ì˜µì…˜ì€ --model ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        if analyzer.check_llm_service() and analyzer.test_llm_connection():
            print("\nâœ… LLM ì„œë¹„ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        else:
            print("\nâŒ LLM ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
        sys.exit(0)

    if not args.sosreport_archive:
        parser.error("ë¶„ì„í•  sosreport ì••ì¶• íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
    if not args.model:
        parser.error("ë¶„ì„ì„ ìœ„í•´ì„œëŠ” --model ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    if not os.path.exists(args.sosreport_archive):
        print(f"âŒ ì…ë ¥ëœ ì••ì¶• íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.sosreport_archive}")
        sys.exit(1)

    os.makedirs(args.output, exist_ok=True)
    
    temp_extract_dir = Path(args.output) / f"temp_{Path(args.sosreport_archive).stem}_{int(time.time())}"
    
    try:
        decompress_sosreport(args.sosreport_archive, str(temp_extract_dir))
        
        parser = SosreportParser(str(temp_extract_dir))
        sos_data = parser.parse()

        base_name = Path(args.sosreport_archive).stem.replace('.tar', '')
        # sar ë°ì´í„°ë§Œ ë”°ë¡œ JSON íŒŒì¼ë¡œ ì €ì¥
        sar_data_path = Path(args.output) / f"{base_name}_sar_data.json"
        try:
            with open(sar_data_path, 'w', encoding='utf-8') as f:
                json.dump(sos_data.get("performance_data", {}), f, indent=2, ensure_ascii=False)
            print(f"âœ… ì¶”ì¶œëœ sar ë°ì´í„° JSON íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ: {sar_data_path}")
        except Exception as e:
            print(f"âŒ ì¶”ì¶œëœ sar ë°ì´í„° JSON ì €ì¥ ì‹¤íŒ¨: {e}")

        # ì „ì²´ íŒŒì‹± ë°ì´í„°ë„ ì €ì¥ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        parsed_data_path = Path(args.output) / f"{base_name}_extracted_data.json"
        try:
            with open(parsed_data_path, 'w', encoding='utf-8') as f:
                json.dump(sos_data, f, indent=2, ensure_ascii=False)
            print(f"âœ… ì „ì²´ ì¶”ì¶œ ë°ì´í„° JSON íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ: {parsed_data_path}")
        except Exception as e:
            print(f"âŒ ì „ì²´ ì¶”ì¶œ ë°ì´í„° JSON ì €ì¥ ì‹¤íŒ¨: {e}")


        prompt = analyzer.create_analysis_prompt(sos_data)
        result = analyzer.perform_ai_analysis(prompt)
        print("âœ… AI ì‹œìŠ¤í…œ ë¶„ì„ ì™„ë£Œ!")
        
        # AI ë¶„ì„ ê²°ê³¼ë¥¼ sos_dataì— ì¶”ê°€í•˜ì—¬ HTML ë³´ê³ ì„œì—ì„œ í•¨ê»˜ ì‚¬ìš©
        sos_data['ai_analysis'] = result

        sos_data['security_news'] = analyzer.fetch_security_news(sos_data)
        
        graphs = analyzer.create_performance_graphs(sos_data.get("performance_data", {}))
        
        results = {}
        if not args.no_html:
            html_path = analyzer.create_html_report(result, sos_data, graphs, args.output, args.sosreport_archive)
            results['html_file'] = html_path
        
        results['sar_data_file'] = str(sar_data_path)
        results['extracted_data_file'] = str(parsed_data_path)

        print("\në¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        if 'html_file' in results:
            print(f"  - HTML ë³´ê³ ì„œ: {results['html_file']}")
        if 'sar_data_file' in results:
            print(f"  - SAR ë°ì´í„° (JSON): {results['sar_data_file']}")
        if 'extracted_data_file' in results:
            print(f"  - ì „ì²´ ì¶”ì¶œ ë°ì´í„° (JSON): {results['extracted_data_file']}")

    except Exception as e:
        print(f"\nâŒ ì „ì²´ ë¶„ì„ ê³¼ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)
    finally:
        if os.path.exists(temp_extract_dir):
            print(f"ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬: {temp_extract_dir}")
            try:
                shutil.rmtree(temp_extract_dir, onerror=rmtree_onerror)
                print("âœ… ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ ì™„ë£Œ.")
            except Exception as e:
                print(f"âŒ ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ì— ìµœì¢… ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}. ìˆ˜ë™ìœ¼ë¡œ ì‚­ì œí•´ì£¼ì„¸ìš”: {temp_extract_dir}")

if __name__ == "__main__":
    main()
